[["index.html", "Loss Data Analytics Second Edition Preface Acknowledgements Contributors Reviewers Version Number For our Readers", " Loss Data Analytics Second Edition An open text authored by the Actuarial Community Preface Date: 02 February 2025 Book Description Loss Data Analytics is an interactive, online, freely available text. The online version contains many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. A subset of the book is available for offline reading in pdf and EPUB formats. The online text will be available in multiple languages to promote access to a worldwide audience. What will success look like? The online text will be freely available to a worldwide audience. The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. Moreover, a subset of the book will be available in pdf format for low-cost printing. The online text will be available in multiple languages to promote access to a worldwide audience. How will the text be used? This book will be useful in actuarial curricula worldwide. It will cover the loss data learning objectives of the major actuarial organizations. Thus, it will be suitable for classroom use at universities as well as for use by independent learners seeking to pass professional actuarial examinations. Moreover, the text will also be useful for the continuing professional development of actuaries and other professionals in insurance and related financial risk management industries. Why is this good for the profession? An online text is a type of open educational resource (OER). One important benefit of an OER is that it equalizes access to knowledge, thus permitting a broader community to learn about the actuarial profession. Moreover, it has the capacity to engage viewers through active learning that deepens the learning process, producing analysts more capable of solid actuarial work. Why is this good for students and teachers and others involved in the learning process? Cost is often cited as an important factor for students and teachers in textbook selection (see a recent post on the $400 textbook). Students will also appreciate the ability to “carry the book around” on their mobile devices. Why loss data analytics? The intent is that this type of resource will eventually permeate throughout the actuarial curriculum. Given the dramatic changes in the way that actuaries treat data, loss data seems like a natural place to start. The idea behind the name loss data analytics is to integrate classical loss data models from applied probability with modern analytic tools. In particular, we recognize that big data (including social media and usage based insurance) are here to stay and that high speed computation is readily available. Project Goal The project goal is to have the actuarial community author our textbooks in a collaborative fashion. To get involved, please visit our Open Actuarial Textbooks Project Site. Acknowledgements Edward Frees acknowledges the John and Anne Oros Distinguished Chair for Inspired Learning in Business which provided seed money to support the project. Frees and his Wisconsin colleagues also acknowledge a Society of Actuaries Center of Excellence Grant that provided funding to support work in dependence modeling and health initiatives. Wisconsin also provided an education innovation grant that provided partial support for the many students who have worked on this project. We acknowledge the Society of Actuaries for permission to use problems from their examinations. We thank Rob Hyndman, Monash University, for allowing us to use his excellent style files to produce the online version of the book. We thank Yihui Xie and his colleagues at Rstudio for the R bookdown package that allows us to produce this book. We also wish to acknowledge the support and sponsorship of the International Association of Black Actuaries in our joint efforts to provide actuarial educational content to all. Contributors The project goal is to have the actuarial community author our textbooks in a collaborative fashion. The following contributors have taken a leadership role in developing Loss Data Analytics. Zeinab Amin is a Professor at the Department of Mathematics and Actuarial Science and Associate Provost for Assessment and Accreditation at the American University in Cairo (AUC). Amin holds a PhD in Statistics and is an Associate of the Society of Actuaries. Amin is the recipient of the 2016 Excellence in Academic Service Award and the 2009 Excellence in Teaching Award from AUC. Amin has designed and taught a variety of statistics and actuarial science courses. Amin’s current area of research includes quantitative risk assessment, reliability assessment, general statistical modelling, and Bayesian statistics. Katrien Antonio, KU Leuven Jean-François Bégin is an Assistant Professor in the Department of Statistics and Actuarial Science at Simon Fraser University in British Columbia, Canada. Bégin holds a PhD in Financial Engineering from HEC Montréal, Canada, and is a Fellow of the Society of Actuaries and of the Canadian Institute of Actuaries. His current research interests include financial modelling, financial econometrics, Bayesian statistics, filtering methods, credit risk, option pricing, and pension economics. Bégin has designed and taught a variety of actuarial finance and actuarial communication courses. Jan Beirlant, KU Leuven Arthur Charpentier is a professor in the Department of Mathematics at the Université du Québec á Montréal. Prior to that, he worked at a large general insurance company in Hong Kong, China, and the French Federation of Insurers in Paris, France. He received a MS on mathematical economics at Université Paris Dauphine and a MS in actuarial science at ENSAE (National School of Statistics) in Paris, and a PhD degree from KU Leuven, Belgium. His research interests include econometrics, applied probability and actuarial science. He has published several books (the most recent one on Computational Actuarial Science with R, CRC) and papers on a variety of topics. He is a Fellow of the French Institute of Actuaries, and was in charge of the ‘Data Science for Actuaries’ program from 2015 to 2018. Curtis Gary Dean is the Lincoln Financial Distinguished Professor of Actuarial Science at Ball State University. He is a Fellow of the Casualty Actuarial Society and a CFA charterholder. He has extensive practical experience as an actuary at American States Insurance, SAFECO, and Travelers. He has served the CAS and actuarial profession as chair of the Examination Committee, first editor-in-chief for Variance: Advancing the Science of Risk, and as a member of the Board of Directors and the Executive Council. He contributed a chapter to Predictive Modeling Applications in Actuarial Science published by Cambridge University Press. Edward (Jed) Frees is an emeritus professor, formerly the Hickman-Larson Chair of Actuarial Science at the University of Wisconsin-Madison. He is a Fellow of both the Society of Actuaries and the American Statistical Association. He has published extensively (a four-time winner of the Halmstad and Prize for best paper published in the actuarial literature) and has written three books. He also is a co-editor of the two-volume series Predictive Modeling Applications in Actuarial Science published by Cambridge University Press. Guojun Gan is an associate professor in the Department of Mathematics at the University of Connecticut, where he has been since August 2014. Prior to that, he worked at a large life insurance company in Toronto, Canada for six years. He received a BS degree from Jilin University, Changchun, China, in 2001 and MS and PhD degrees from York University, Toronto, Canada, in 2003 and 2007, respectively. His research interests include data mining and actuarial science. He has published several books and papers on a variety of topics, including data clustering, variable annuity, mathematical finance, applied statistics, and VBA programming. Lisa Gao is a PhD candidate in the Risk and Insurance department at the University of Wisconsin-Madison. She holds a BMath in Actuarial Science and Statistics from the University of Waterloo and is an Associate of the Society of Actuaries. José Garrido, Concordia University Lei (Larry) Hua is an Associate Professor of Actuarial Science at Northern Illinois University. He earned a PhD degree in Statistics from the University of British Columbia. He is an Associate of the Society of Actuaries. His research work focuses on multivariate dependence modeling for non-Gaussian phenomena and innovative applications for financial and insurance industries. Noriszura Ismail is a Professor and Head of Actuarial Science Program, Universiti Kebangsaan Malaysia (UKM). She specializes in Risk Modelling and Applied Statistics. She obtained her BSc and MSc (Actuarial Science) in 1991 and 1993 from University of Iowa, and her PhD (Statistics) in 2007 from UKM. She also passed several papers from Society of Actuaries in 1994. She has received several research grants from Ministry of Higher Education Malaysia (MOHE) and UKM, totaling about MYR1.8 million. She has successfully supervised and co-supervised several PhD students (13 completed and 11 on-going). She currently has about 180 publications, consisting of 88 journals and 95 proceedings. Joseph H.T. Kim, Ph.D., FSA, CERA, is Associate Professor of Applied Statistics at Yonsei University, Seoul, Korea. He holds a Ph.D. degree in Actuarial Science from the University of Waterloo, at which he taught as Assistant Professor. He also worked in the life insurance industry. He has published papers in Insurance Mathematics and Economics, Journal of Risk and Insurance, Journal of Banking and Finance, ASTIN Bulletin, and North American Actuarial Journal, among others. Nii-Armah Okine is an assistant professor at the Mathematical Sciences Department at Appalachian State University. He holds a Ph.D. in Business (Actuarial Science) from the University of Wisconsin - Madison and obtained his master’s degree in Actuarial science from Illinois State University. His research interest includes micro-level reserving, joint longitudinal-survival modeling, dependence modeling, micro-insurance, and machine learning. Rajesh (Raj) Sahasrabuddhe is a Partner and Philadelphia Office Leader with Oliver Wyman Actuarial Consulting. Raj is a Fellow of the Casualty Actuarial Society (CAS), an Associate of the Canadian Institute of Actuaries, and a Member of the American Academy of Actuaries. Raj has been an active volunteer with CAS Admissions committees throughout his career, including a term as Chairperson of the Syllabus Committee from 2010 to 2013. He currently serves on the MAS-II Examination Committee. He has authored or co-authored papers that have appeared on syllabi for both the CAS and Society of Actuaries. Emine Selin Sarıdaş is a doctoral candidate in the Statistics department of Mimar Sinan University. She holds a bachelor degree in Actuarial Science with a minor in Economics and a master degree in Actuarial Science from Hacettepe University. Her research interest includes dependence modeling, regression, loss models and life contingencies. Peng Shi is an associate professor in the Risk and Insurance Department at the Wisconsin School of Business. He is also the Charles &amp; Laura Albright Professor in Business and Finance. Professor Shi is an Associate of the Casualty Actuarial Society (ACAS) and a Fellow of the Society of Actuaries (FSA). He received a Ph.D. in actuarial science from the University of Wisconsin-Madison. His research interests are problems at the intersection of insurance and statistics. He has won several research awards, including the Charles A. Hachemeister Prize, the Ronald Bornhuetter Loss Reserve Prize, and the American Risk and Insurance Association Prize. Nariankadu D. Shyamalkumar (Shyamal) is an associate professor in the Department of Statistics and Actuarial Science at The University of Iowa. He is an Associate of the Society of Actuaries, and has volunteered in various elected and non-elected roles within the SoA. Having a broad theoretical interest as well as interest in computing, he has published in prominent actuarial, computer science, probability theory, and statistical journals. Moreover, he has worked in the financial industry, and since then served as an independent consultant to the insurance industry. He has experience educating actuaries in both Mexico and the US, serving in the roles of directing an undergraduate program, and as a graduate adviser for both masters and doctoral students. Jianxi Su is an Assistant Professor at the Department of Statistics at Purdue University. He is the Associate Director of Purdue’s Actuarial Science. Prior to joining Purdue in 2016, he completed the PhD at York University (2012-2015). He obtained the Fellow of the Society of Actuaries (FSA) in 2017. His research expertise are in dependence modelling, risk management, and pricing. During the PhD candidature, Jianxi also worked as a research associate at the Model Validation and ORSA Implementation team of Sun Life Financial (Toronto office). Chong It Tan is a senior lecturer at Macquarie University in Australia, where he has served as the undergraduate actuarial program director since 2018. He obtained his PhD in 2015 from Nanyang Technological University in Singapore. He is a fully qualified actuary, holding the credentials from both the US Society of Actuaries and Australian Actuaries Institute. His major research interests are mortality modelling, longevity risk management and bonus-malus systems. Tim Verdonck is associate professor at the University of Antwerp. He has a degree in Mathematics and a PhD in Science: Mathematics, obtained at the University of Antwerp. During his PhD he successfully took the Master in Insurance and the Master in Financial and Actuarial Engineering, both at KU Leuven. His research focuses on the adaptation and application of robust statistical methods for insurance and finance data. Krupa Viswanathan is an Associate Professor in the Risk, Insurance and Healthcare Management Department in the Fox School of Business, Temple University. She is an Associate of the Society of Actuaries. She teaches courses in Actuarial Science and Risk Management at the undergraduate and graduate levels. Her research interests include corporate governance of insurance companies, capital management, and sentiment analysis. She received her Ph.D. from The Wharton School of the University of Pennsylvania. Reviewers Our goal is to have the actuarial community author our textbooks in a collaborative fashion. Part of the writing process involves many reviewers who generously donated their time to help make this book better. They are: Yair Babab David Back, Liberty Mutual Chunsheng Ban, Ohio State University Vytaras Brazauskas, University of Wisconsin - Milwaukee Yvonne Chueh, Central Washington University Chun Yong Chew, Universiti Tunku Abdul Rahman (UTAR) Benjamin Côté, Université Laval Eren Dodd, University of Southampton Gordon Enderle, University of Wisconsin - Madison Rob Erhardt, Wake Forest University Runhun Feng, University of Illinois Brian Hartman, Brigham Young University Liang (Jason) Hong, University of Texas at Dallas Fei Huang, Australian National University Hirokazu (Iwahiro) Iwasawa Himchan Jeong, University of Connecticut Min Ji, Towson University Paul Herbert Johnson, University of Wisconsin - Madison Dalia Khalil, Cairo University Samuel Kolins, Lebonan Valley College Andrew Kwon-Nakamura, Zurich North America Ambrose Lo, University of Iowa Mélina Mailhot, Concordia University Mark Maxwell, University of Texas at Austin Tatjana Miljkovic, Miami University Bell Ouelega, American University in Cairo Zhiyu (Frank) Quan, University of Connecticut Jiandong Ren, Western University Margie Rosenberg, University of Wisconsin - Madison Rajesh V. Sahasrabuddhe, Oliver Wyman Sherly Paola Alfonso Sanchez, Universidad Nacional de Colombia Ranee Thiagarajah, Illinois State University Ping Wang, Saint Johns University Chengguo Weng, University of Waterloo Toby White, Drake University Michelle Xia, Northern Illinois University Di (Cindy) Xu, University of Nebraska - Lincoln Lina Xu, Columbia University Lu Yang, University of Amsterdam Chun Yong Jorge Yslas, University of Copenhagen Jeffrey Zheng, Temple University Hongjuan Zhou, Arizona State University Other Collaborators Alyaa Nuval Binti Othman, Aisha Nuval Binti Othman, and Khairina (Rina) Binti Ibraham were three of many students at the Univeristy of Wiscinson-Madison that helped with the text over the years. Maggie Lee, Macquarie University, and Anh Vu (then at University of New South Wales) contributed the end of the section quizzes. Jeffrey Zheng, Temple University, Lu Yang (University of Amsterdam), and Paul Johnson, University of Wisconsin-Madison, led the work on the glossary. Version Number This is Version 2.0, October 2024. Edited by Hélène Cossette, Edward (Jed) Frees, Brian Hartman, and Tim Higgins. Version 1.1, August 2020. Edited by Edward (Jed) Frees and Paul Johnson. Version 1.0, January 2020, was edited by Edward (Jed) Frees. You can also access pdf and epub (current and older) versions of the text in our Offline versions of the text. For our Readers We hope that you find this book worthwhile and even enjoyable. For your convenience, at our Github Landing site (https://openacttexts.github.io/), you will find links to the book that you can (freely) download for offline reading, including a pdf version (for Adobe Acrobat) and an EPUB version suitable for mobile devices. Data for running our examples are available at the same site. In developing this book, we are emphasizing the online version that has lots of great features such as a glossary, code and solutions to examples that you can be revealed interactively. For example, you will find that the statistical code is hidden and can only be seen by clicking on terms such as R Code for Frequency Table Insample &lt;- read.csv(&quot;Insample.csv&quot;, header = T, na.strings = c(&quot;.&quot;), stringsAsFactors = FALSE) Insample2010 &lt;- subset(Insample, Year == 2010) table(Insample2010$Freq) We hide the code because we don’t want to insist that you use the R statistical software (although we like it). Still, we encourage you to try some statistical code as you read the book – we have opted to make it easy to learn R as you go. We have set up a separate R Code for Loss Data Analytics site to explain more of the details of the code. Like any book, we have a set of notations and conventions. It will probably save you time if you regularly visit our Appendix Chapter ?? to get used to ours. Freely available, interactive textbooks represent a new venture in actuarial education and we need your input. Although a lot of effort has gone into the development, we expect hiccoughs. Please let your instructor know about opportunities for improvement, write us through our project site, or contact chapter contributors directly with suggested improvements. This work is licensed under a Creative Commons Attribution 4.0 International License. "],["ChapSummaryDistributions.html", "Chapter 1 Appendix D: Summary of Distributions 1.1 Discrete Distributions 1.2 Continuous Distributions 1.3 Limited Expected Values", " Chapter 1 Appendix D: Summary of Distributions User Notes The R functions are from the packages actuar and invgamma. Tables appear when first loaded by the browser. To hide them, click on one of the distributions, e.g., Poisson, and then click on the Hide button. More information on the R codes is available at the R Codes for Loss Data Analytics site. 1.1 Discrete Distributions Overview. This section summarizes selected discrete probability distributions used throughout Loss Data Analytics. Relevant functions and R code are provided. 1.1.1 The (a,b,0) Class Poisson Geometric Binomial Negative Binomial Hide Poisson Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\lambda&gt;0 \\\\ \\hline ~~p_0 &amp; e^{-\\lambda} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{e^{-\\lambda}\\lambda^k}{k!} \\\\ ~~p_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\lambda \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\lambda \\\\ \\hline \\small{\\text{Probability generating function}} &amp; e^{\\lambda(z-1)} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=0 \\\\ &amp; b=\\lambda \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dpois}(x=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{ppois}(p=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qpois}(q=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rpois}(n=, lambda=\\lambda) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Geometric Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\beta&gt;0 \\\\ \\hline ~~p_0 &amp; \\frac{1}{1+\\beta} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{\\beta^k}{(1+\\beta)^{k+1}} \\\\ ~~p_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\beta \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\beta(1+\\beta) \\\\ \\hline \\small{\\text{Probability generating function}} &amp; [1-\\beta(z-1)]^{-1} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{\\beta}{1+\\beta} \\\\ &amp; b=0 \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dgeom}(x=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pgeom}(p=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qgeom}(q=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rgeom}(n=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Binomial Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; 0&lt;q&lt;1,~\\text{m is an integer} \\\\ &amp; 0 \\leq k \\leq m\\\\ \\hline ~~p_0 &amp;(1-q)^m \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\binom{m}{k}q^k(1-q)^{m-k} \\\\ ~~p_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; mq \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; mq(1-q) \\\\ \\hline \\small{\\text{Probability generating function}} &amp; [1+q(z-1)]^m \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{-q}{1-q} \\\\ &amp; b=\\frac{(m+1)q}{1-q} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dbinom}(x=, size=m, prob=q) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pbinom}(p=, size=m, prob=q) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qbinom}(q=, size=m, prob=q) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rbinom}(n=, size=m, prob=q) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Negative Binomial Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; r&gt;0, \\beta&gt;0 \\\\ \\hline ~~p_0 &amp; (1+\\beta)^{-r} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{r(r+1)\\cdots(r+k-1)\\beta^k}{k!(1+\\beta)^{r+k}} \\\\ ~~p_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; r\\beta \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; r\\beta(1+\\beta) \\\\ \\hline \\small{\\text{Probability generating function}} &amp; [1-\\beta(z-1)]^{-r} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{\\beta}{1+\\beta} \\\\ &amp; b=\\frac{(r-1)\\beta}{1+\\beta} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dnbinom}(x=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pnbinom}(p=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qnbinom}(q=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rnbinom}(n=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\end{array} \\end{matrix} \\] 1.1.2 The (a,b,1) Class Zero Truncated Poisson Zero Truncated Geometric Zero Truncated Binomial Zero Truncated Negative Binomial Logarithmic Hide Zero Truncated Poisson Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\lambda&gt;0 \\\\ \\hline ~~p^T_1 &amp; \\frac{\\lambda}{e^\\lambda-1} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{\\lambda^k}{k!(e^\\lambda-1)} \\\\ ~~p^T_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\frac{\\lambda}{1-e^{-\\lambda}} \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\frac{\\lambda[1-(\\lambda+1)e^{-\\lambda}]}{(1-e^{-\\lambda})^2} \\\\ \\hline \\small{\\text{Probability generating function}} &amp; \\frac{e^{\\lambda z}-1}{e^\\lambda-1} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=0 \\\\ &amp; b=\\lambda \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dztpois}(x=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pztpois}(p=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qztpois}(q=, lambda=\\lambda) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rztpois}(n=, lambda=\\lambda) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Zero Truncated Geometric Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\beta&gt;0 \\\\ \\hline ~~p^T_1 &amp; \\frac{1}{1+\\beta} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{\\beta^{k-1}}{(1+\\beta)^k} \\\\ ~~p^T_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; 1+\\beta \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\beta(1+\\beta) \\\\ \\hline \\small{\\text{Probability generating function}} &amp; \\frac{[1-\\beta(z-1)]^{-1}-(1+\\beta)^{-1}}{1-(1+\\beta)^{-1}} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{\\beta}{1+\\beta} \\\\ &amp; b=0 \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dztgeom}(x=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pztgeom}(p=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qztgeom}(q=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rztgeom}(n=, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Zero Truncated Binomial Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; 0&lt;q&lt;1,~\\text{m is an integer} \\\\ &amp; 0 \\leq k \\leq m\\\\ \\hline ~~p^T_1 &amp; \\frac{m(1-q)^{m-1}q}{1-(1-q)^m} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{\\binom{m}{k}q^k(1-q)^{m-k}}{1-(1-q)^m} \\\\ ~~p^T_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\frac{mq}{1-(1-q)^m} \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\frac{mq[(1-q)-(1-q+mq)(1-q)^m]}{[1-(1-q)^m]^2} \\\\ \\hline \\small{\\text{Probability generating function}} &amp; \\frac{[1+q(z-1)^m]-(1-q)^m}{1-(1-q)^m} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{-q}{1-q} \\\\ &amp; b=\\frac{(m+1)q}{1-q} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commmands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dztbinom}(x=, size=m, prob=p) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pztbinom}(p=, size=m, prob=p) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qztbinom}(q=, size=m, prob=p) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rztbinom}(n=, size=m, prob=p) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Zero Truncated Negative Binomial Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; r&gt;-1, r\\neq0 \\\\ \\hline ~~p^T_1 &amp; \\frac{r\\beta}{(1+\\beta)^{r+1}-(1+\\beta)} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{r(r+1)\\cdots(r+k-1)}{k![(1+\\beta)^r-1]}(\\frac{\\beta}{1+\\beta})^k \\\\ ~~p^T_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\frac{r\\beta}{1-(1+\\beta)^{-r}} \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\frac{r\\beta[(1+\\beta)-(1+\\beta+r\\beta)(1+\\beta)^{-r}]}{[1-(1+\\beta)^{-r}]^2} \\\\ \\hline \\small{\\text{Probability generating function}} &amp; \\frac{[1-\\beta(z-1)]^{-r}-(1+\\beta)^{-r}}{1-(1+\\beta)^{-r}} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{\\beta}{1+\\beta} \\\\ &amp; b=\\frac{(r-1)\\beta}{1+\\beta} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dztnbinom}(x=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pztnbinom}(p=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qztnbinom}(q=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rztnbinom}(n=, size=r, prob=\\frac{1}{1+\\beta}) \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Logarithmic Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\beta&gt;0 \\\\ \\hline ~~p^T_1 &amp; \\frac{\\beta}{(1+\\beta)ln(1+\\beta)} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\frac{\\beta^k}{k(1+\\beta)^k \\ln (1+\\beta)} \\\\ ~~p^T_k &amp; \\\\ \\hline \\small{\\text{Expected value}} &amp; \\frac{\\beta}{\\ln (1+\\beta)} \\\\ ~~\\mathrm{E}[N] &amp; \\\\ \\hline \\small{\\text{Variance}} &amp; \\frac{\\beta[1+\\beta-\\frac{\\beta}{ln(1+\\beta)}]}{\\ln (1+\\beta)} \\\\ \\hline \\small{\\text{Probability generating function}} &amp; 1-\\frac{ln[1-\\beta(z-1)]}{\\ln (1+\\beta)} \\\\ ~~P(z) &amp; \\\\ \\hline a \\small{\\text{ and }} b \\small{\\text{ for recursion}} &amp; a=\\frac{\\beta}{1+\\beta} \\\\ &amp; b=\\frac{-\\beta}{1+\\beta} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Probability mass function}} &amp; \\text{dnbinom}(x=,prob=\\frac{\\beta}{1+\\beta}) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pnbinom}(p=,prob=\\frac{\\beta}{1+\\beta}) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qnbinom}(q=,prob=\\frac{\\beta}{1+\\beta}) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rnbinom}(n=,prob=\\frac{\\beta}{1+\\beta}) \\\\ \\hline \\end{array} \\end{matrix} \\] 1.2 Continuous Distributions Overview. This section summarizes selected continuous probability distributions used throughout Loss Data Analytics. Relevant functions, R code, and illustrative graphs are provided. 1.2.1 One Parameter Distributions Exponential Inv Exponential Single Parameter Pareto Hide Exponential Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{\\theta}e^{-x/\\theta} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-e^{-x/\\theta} \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k\\Gamma(k+1) \\\\ ~~\\mathrm{E}[X^k] &amp; k&gt;-1 \\\\ \\hline VaR_p(x) &amp; -\\theta \\ln (1-p) \\\\ \\hline \\small{\\text{Limited Expected Value}} &amp; \\theta(1-e^{-x/\\theta}) \\\\ ~~\\mathrm{E}[X\\wedge x] &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dexp}(x=, rate=1/\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pexp}(p=, rate=1/\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qexp}(q=, rate=1/\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rexp}(n=, rate=1/\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dexp(X, rate = 1/theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Exponential Distribution&quot;) Hide Inverse Exponential Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\theta e^{-\\theta/x}}{x^2} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; e^{-\\theta/x} \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k\\Gamma(1-k) \\\\ ~~\\mathrm{E}[X^k] &amp; k&lt;1 \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\theta^kG(1-k;\\theta/x)+x^k (1 - e^{-\\theta/x}) \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvexp}(x=, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvexp}(p=, scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvexp}(q=, scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvexp}(n=, scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph theta &lt;- 0.01 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dinvexp(X, rate = 1/theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Inverse Exponential Distribution&quot;) Hide Single Parameter Pareto Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta~\\text{is known},~x&gt;\\theta, \\alpha &gt; 0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\alpha\\theta^\\alpha}{x^{\\alpha+1}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-(\\theta/x)^\\alpha \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\alpha\\theta^k}{\\alpha-k} \\\\ ~~\\mathrm{E}[X^k] &amp; k &lt; \\alpha \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\alpha\\theta^k}{\\alpha-k}-\\frac{k\\theta^{\\alpha}}{(\\alpha-k)x^{\\alpha-k}} \\\\ &amp; x \\geq\\theta \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dpareto1}(x=, shape=\\alpha,min=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{ppareto1}(p=, shape=\\alpha,min=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qpareto1}(q=, shape=\\alpha,min=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rpareto1}(n=, shape=\\alpha,min=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 3 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dpareto1(X, shape = alpha, min = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Single Parameter Pareto Distribution&quot;) 1.2.2 Two Parameter Distributions Pareto Inv Pareto Loglogistic Paralogistic Gamma Inv Gamma Weibull Inv Weibull Uniform Normal Hide Pareto Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\alpha&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\alpha\\theta^\\alpha}{(x+\\theta)^{\\alpha+1}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-\\Big(\\frac{\\theta}{x+\\theta}\\Big)^\\alpha \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(k+1)\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)} \\\\ ~~\\mathrm{E}[X^k] &amp; -1&lt;k&lt;\\alpha \\\\ \\hline \\small{\\text{Limited Expected Value:}}~\\alpha\\neq1 &amp; \\frac{\\theta}{\\alpha-1}\\Big[1-\\Big(\\frac{\\theta}{x+\\theta}\\Big)^{\\alpha-1}\\Big] \\\\ ~~\\mathrm{E}[X\\wedge x] &amp; \\\\ \\hline \\small{\\text{Limited Expected Value:}}~\\alpha=1 &amp; -\\theta \\ln \\left(\\frac{\\theta}{x+\\theta}\\right) \\\\ ~~\\mathrm{E}[X\\wedge x] &amp; \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(k+1)\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)}\\beta(k+1,\\alpha-k;\\frac{x}{x+\\theta})+x^k(\\frac{\\theta}{x+\\theta})^\\alpha \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dpareto}(x=, shape=\\alpha, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{ppareto}(p=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qpareto}(q=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rpareto}(n=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 3 theta &lt;- 200 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = actuar::dpareto(X, shape = alpha, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Pareto Distribution&quot;) Hide Inverse Pareto Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\tau&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\tau\\theta x^{\\tau-1}}{(x+\\theta)^\\tau-1} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\Big(\\frac{x}{x+\\theta}\\Big)^\\tau \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(\\tau+k)\\Gamma(1-k)}{\\Gamma(\\tau)} \\\\ ~~\\mathrm{E}[X^k] &amp; -\\tau&lt;k&lt;1 \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\theta^k\\tau\\int^{x/(x+\\theta)}_0~y^{\\tau+k-1}(1-y)^{-k}dy+x^k[1-\\Big(\\frac{x}{x+\\theta}\\Big)^\\tau] \\\\ &amp; k&gt;-\\tau \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvpareto}(x=, shape=\\tau, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvpareto}(p=, shape=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvpareto}(q=, shape=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvpareto}(n=, shape=\\tau,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph tau &lt;- 5 theta &lt;- 100 X &lt;- seq(from = 0, to = 3000, by = 1) plot(x = X, y = dinvpareto(X, shape = tau, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Inverse Pareto Distribution&quot;) Hide Loglogistic Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\gamma &gt; 0, u=\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\gamma(x/\\theta)^\\gamma}{x[1+(x/\\theta)^\\gamma]^2} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; u \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k\\Gamma(1+(k/\\gamma))\\Gamma(1-(k/\\gamma)) \\\\ ~~\\mathrm{E}[X^k] &amp; -\\gamma&lt;k&lt;\\gamma \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\theta^k\\Gamma(1+(k/\\gamma))\\Gamma(1-(k/\\gamma))\\beta(1+(k/\\gamma),1-(k/\\gamma);u)+x^k(1-u) \\\\ &amp; k&gt;-\\gamma \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph dloglogistic &lt;- function(x, gamma, theta) { p = gamma * (x/theta)^gamma/(x * (1 + (x/theta)^gamma)^2) return(p) } gamma &lt;- 2 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dloglogistic(X, gamma = gamma, theta = theta), type = &quot;l&quot;, col = &quot;red&quot;) Hide Paralogistic Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\alpha&gt;0, u=\\frac{1}{1+(x/\\theta)^\\alpha} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\alpha^2(x/\\theta)^\\alpha}{x[1+(x/\\theta)^\\alpha]^{\\alpha+1}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-u^\\alpha \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(1+(k/\\alpha))\\Gamma(\\alpha-(k/\\alpha))}{\\Gamma(\\alpha)} \\\\ ~~\\mathrm{E}[X^k] &amp; -\\alpha&lt;k&lt;\\alpha^2 \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(1+(k/\\alpha))\\Gamma(\\alpha-(k/\\alpha))}{\\Gamma(\\alpha)}\\beta(1+(k/\\alpha),\\alpha-(k/\\alpha);1-u)+x^ku^\\alpha \\\\ &amp; k&gt;-\\alpha \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dparalogis}(x=, shape=\\alpha, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pparalogis}(p=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qparalogis}(q=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rparalogis}(n=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 2 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dparalogis(X, shape = alpha, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Paralogistic Distribution&quot;) Hide Gamma Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0,~\\alpha&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{\\theta^{\\alpha}\\Gamma(\\alpha)}x^{\\alpha-1}e^{-x/\\theta} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\Gamma(\\alpha;\\frac{x}{\\theta}) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k\\frac{\\Gamma(\\alpha+k)}{\\Gamma(\\alpha)} \\\\ ~~\\mathrm{E}[X^k] &amp; k&gt;-\\alpha \\\\ \\hline &amp; \\frac{\\theta^k\\Gamma(k+\\alpha)}{\\Gamma(\\alpha)}\\Gamma(k+\\alpha; x/\\theta)+x^k[1-\\Gamma(\\alpha; x/\\theta)] \\\\ ~~\\mathrm{E}[X\\wedge x]^k &amp; k &gt; -\\alpha \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\small{\\text{Density function}} &amp; \\text{dgamma}(x=, shape=\\alpha, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pgamma}(p=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qgamma}(q=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rgamma}(n=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 2 theta &lt;- 50 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dgamma(X, shape = alpha, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Gamma Distribution&quot;) Hide Inverse Gamma Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{(\\theta/x)^\\alpha e^{-\\theta/x}}{x\\Gamma(\\alpha)} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-\\Gamma(\\alpha;\\theta/x) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)} \\\\ ~~\\mathrm{E}[X^k] &amp; k&lt;\\alpha \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)}[1-\\Gamma(\\alpha-k;\\theta/x)]+x^k\\Gamma(\\alpha;\\theta/x) \\\\ &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvgamma}(x=, shape=\\alpha, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvgamma}(p=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvgamma}(q=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvgamma}(n=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 3 theta &lt;- 100 X &lt;- seq(from = 0, to = 400, by = 1) plot(x = X, y = dinvgamma(X, shape = alpha, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Inverse Gamma Distribution&quot;) Hide Weibull Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0,\\alpha&gt;0 \\\\ \\hline\\ \\small{\\text{Probability density}} &amp; \\frac{\\alpha \\Big(\\frac{x}{\\theta}\\Big)^\\alpha \\exp\\Big(-\\Big(\\frac{x}{\\theta}\\Big)^\\alpha\\Big)}{x} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-\\exp\\Big(-\\Big(\\frac{x}{\\theta}\\Big)^\\alpha\\Big) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k \\Gamma(1 + \\frac{k}{\\alpha}) \\\\ ~~\\mathrm{E}[X^k] &amp; k&gt;-\\alpha \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\theta^k\\Gamma(1+\\frac{k}{\\alpha})\\Gamma\\Big[1+\\frac{k}{\\alpha};\\Big(\\frac{x}{\\theta}\\Big)^\\alpha\\Big]+x^k\\exp\\Big(-\\Big(\\frac{x}{\\theta}\\Big)^\\alpha\\Big) \\\\ &amp; k&gt;-\\alpha \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dweibull}(x=, shape=\\alpha, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pweibull}(p=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qweibull}(q=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rweibull}(n=, shape=\\alpha,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 2 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dweibull(X, shape = alpha, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Weibull Distribution&quot;) Hide Inverse Weibull Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0,\\tau&gt;0 \\\\ \\hline\\ \\small{\\text{Probability density}} &amp; \\frac{\\tau(\\theta/x)^\\tau \\exp\\Big(-\\Big(\\frac{\\theta}{x}\\Big)^\\tau\\Big)}{x} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\exp\\Big(-\\Big(\\frac{\\theta}{x}\\Big)^\\tau\\Big) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\theta^k\\Gamma(1-(k/\\tau)) \\\\ ~~\\mathrm{E}[X^k] &amp; k&lt;\\tau \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\theta^k\\Gamma(1-(k/\\tau))[1-\\Gamma(1-(k/\\tau);(\\theta/x)^\\tau)]+x^k[1-e^{-(\\theta/x)^\\tau}] \\\\ &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvweibull}(x=, shape=\\tau, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvweibull}(p=, shape=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvweibull}(q=, shape=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvweibull}(n=, shape=\\tau,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph tau &lt;- 5 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dinvweibull(X, shape = tau, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Inverse Weibull Distribution&quot;) Hide Uniform Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; -\\infty&lt;\\alpha&lt;\\beta&lt;\\infty \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{\\beta-\\alpha} \\\\ \\text{f(x)} &amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\frac{x-\\alpha}{\\beta-\\alpha} \\\\ ~~F(x) &amp; \\\\ \\hline \\text{Mean} &amp; \\frac{\\beta+\\alpha}{2} \\\\ \\text{E[X]} &amp; \\\\ \\hline \\text{Variance} &amp; \\frac{(\\beta-\\alpha)^2}{12} \\\\ E[(X-\\mu)^2] &amp; \\\\ \\hline \\mathrm{E}[(X-\\mu)^k] &amp; \\mu_k=0~~~\\text{for odd }\\textit{k} \\\\ &amp; \\mu_k=\\frac{(\\beta-\\alpha)^k}{2^k (k+1)}~~~\\text{for even }\\textit{k} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dunif}(x=, min=a, max=b) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{punif}(p=, min=a, max=b) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qunif}(q=, min=a, max=b) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{runif}(n=, min=a, max=b) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 50 beta &lt;- 100 X &lt;- seq(alpha, beta, 1) plot(x = X, y = dunif(X, alpha, beta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Continuous Uniform Distribution&quot;) Hide Normal Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; -\\infty&lt;\\mu&lt;\\infty,~\\sigma&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2}\\right) \\\\ \\text{f(x)} &amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\Phi\\left(\\frac{x-\\mu}{\\sigma}\\right) \\\\ ~~F(x) &amp; \\\\ \\hline \\text{Mean} &amp; \\mu \\\\ \\text{E[X]} &amp; \\\\ \\hline \\text{Variance} &amp; \\sigma^2 \\\\ E[(X-\\mu)^2] &amp; \\\\ \\hline \\mathrm{E}[(x-\\mu)^k] &amp; \\mu_k=0~~~\\text{for even k} \\\\ &amp; \\mu_k=\\frac{k!\\sigma^2}{(\\frac{k}{2})! 2^{k/2}}~~~\\text{for odd k} \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dnorm}(x=, mean=\\mu, sd=\\sigma) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pnorm}(p=, mean=\\mu, sd=\\sigma) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qnorm}(q=, mean=\\mu, sd=\\sigma) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rnorm}(n=, mean=\\mu, sd=\\sigma) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph mu &lt;- 100 sigma &lt;- 10 X &lt;- seq(from = 0, to = 200, by = 1) plot(x = X, y = dnorm(X, mean = mu, sd = sigma), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Normal Distribution&quot;) Hide Cauchy Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; -\\infty &lt;\\alpha &lt;\\infty, \\beta&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{\\pi\\beta}[1+\\left( \\frac{x-\\alpha}{\\beta}\\right)^2]^{-1} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dcauchy}(x=, location=\\alpha, scale=\\beta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pcauchy}(p=, location=\\alpha, scale=\\beta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qcauchy}(q=, location=\\alpha, scale=\\beta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rcauchy}(n=, location=\\alpha, scale=\\beta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 50 beta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dcauchy(X, location = alpha, scale = beta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Cauchy Distribution&quot;) 1.2.3 Three Parameter Distributions Generalized Pareto Burr Inv Burr Hide Generalized Pareto Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\alpha&gt;0, \\tau&gt;0, u=\\frac{x}{x+\\theta} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\Gamma(\\alpha+\\tau)}{\\Gamma(\\alpha)\\Gamma(\\tau)}\\frac{\\theta^\\alpha x^{\\tau-1}}{(x+\\theta)^{\\alpha+\\tau}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\beta(\\tau,\\alpha;u) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(\\tau+1)\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)\\Gamma(\\tau)} \\\\ ~~~~\\mathrm{E}[X^k] &amp; -\\tau&lt;k&lt;\\alpha \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(\\tau+k)\\Gamma(\\alpha-k)}{\\Gamma(\\alpha)\\Gamma(\\tau)}\\beta(\\tau+k,\\alpha-k;u)+x^k[1-\\beta(\\tau,\\alpha;u)] \\\\ &amp; k&gt;-\\tau \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dgenpareto}(x=, shape1=\\alpha, shape2=\\tau, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pgenpareto}(q=, shape1=\\alpha, shape2=\\tau, scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qgenpareto}(p=, shape1=\\alpha, shape2=\\tau, scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rgenpareto}(r=, shape1=\\alpha, shape2=\\tau, scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 3 tau &lt;- 5 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dgenpareto(X, shape1 = alpha, shape2 = tau, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Generalized Pareto Distribution&quot;) Hide Burr Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\alpha&gt;0, \\gamma&gt;0, u=\\frac{1}{1+(x/\\theta)^\\gamma} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\alpha\\gamma(x/\\theta)^\\gamma}{x[1+(x/\\theta)^\\gamma]^{\\alpha+1}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; 1-u^\\alpha \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(1+(k/\\gamma))\\Gamma(\\alpha-(k/\\gamma))}{\\Gamma(\\alpha)} \\\\ ~~~~\\mathrm{E}[X^k] &amp; -\\gamma&lt;k&lt;\\alpha\\gamma \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(1+(k/\\gamma))\\Gamma(\\alpha-(k/\\gamma))}{\\Gamma(\\alpha)}\\beta(1+(k/\\gamma),\\alpha-(k/\\gamma);1-u)+x^ku^\\alpha \\\\ &amp; k&gt;-\\gamma \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dburr}(x=, shape1=\\alpha, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pburr}(p=, shape1=\\alpha, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qburr}(q=, shape1=\\alpha, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rburr}(n=, shape1=\\alpha, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph alpha &lt;- 2 gamma &lt;- 3 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dburr(X, shape1 = alpha, shape2 = gamma, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Burr Distribution&quot;) Hide Inverse Burr Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\tau&gt;0, \\gamma&gt;0, u=\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\tau\\gamma(x/\\theta)^{\\tau \\gamma}}{x[1+(x/\\theta)^\\gamma]^{\\tau+1}} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; u^\\tau \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(\\tau+(k/\\gamma))\\Gamma(1-(k/\\gamma))}{\\Gamma(\\tau)} \\\\ ~~~~\\mathrm{E}[X^k] &amp; -\\tau\\gamma&lt;k&lt;\\gamma \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(\\tau+(k/\\gamma))\\Gamma(1-(k/\\gamma))}{\\Gamma(\\tau)}\\beta(\\tau+(k/\\gamma),1-(k/\\gamma);u)+x^k[1-u^\\tau] \\\\ &amp; k&gt;-\\tau\\gamma \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvburr}(x=, shape1=\\tau, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvburr}(p=, shape1=\\tau, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvburr}(q=, shape1=\\tau, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvburr}(n=, shape1=\\tau, shape2=\\gamma, scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph tau &lt;- 2 gamma &lt;- 3 theta &lt;- 100 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dinvburr(X, shape1 = tau, shape2 = gamma, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Inverse Burr Distribution&quot;) 1.2.4 Four Parameter Distribution GB2 Hide Generalized Beta of the Second Kind (GB2) Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\alpha_1&gt;0, \\alpha_2&gt;0, \\sigma&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{(x/\\theta)^{\\alpha_2/\\sigma}}{x \\sigma~\\mathrm{B}\\left( \\alpha_1,\\alpha_2\\right)\\left\\lbrack 1 + \\left( x/\\theta \\right)^{1/\\sigma} \\right\\rbrack^{\\alpha_1 + \\alpha_2}} \\\\ ~~ \\small{\\text{function }} f(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^{k}~\\mathrm{B}\\left( \\alpha_1 +k \\sigma,\\alpha_2 - k \\sigma \\right)}{\\mathrm{B}\\left( \\alpha_1,\\alpha_2 \\right)} \\\\ ~~~~\\mathrm{E}[X^k] &amp; \\textit{k}&gt;0 \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands Please see the R Codes for Loss Data Analytics site for information about this distribution. 1.2.5 Other Distributions Lognormal Inv Gaussian Hide Lognormal Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; -\\infty &lt;\\mu &lt;\\infty, \\sigma&gt;0 \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{1}{x\\sqrt{2\\pi}\\sigma} \\exp\\left( -\\frac{(\\ln x-\\mu)^2}{2\\sigma^2}\\right) \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\Phi\\left(\\frac{\\ln (x)-\\mu}{\\sigma}\\right) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\exp(k\\mu+\\frac{k^2\\sigma^2}{2}) \\\\ ~~\\mathrm{E}[X^k] &amp; \\\\ \\hline \\small{\\text{Limited Expected Value}} &amp; \\exp\\Big(k\\mu+\\frac{k^2\\sigma^2}{2}\\Big)\\Phi\\Big(\\frac{\\ln (x)-\\mu-k\\sigma^2}{\\sigma}\\Big)+x^k\\Big[1-\\Phi\\Big(\\frac{\\ln (x)-\\mu}{\\sigma}\\Big)\\Big] \\\\ ~~\\mathrm{E}[X\\wedge x] &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph dlognorm &lt;- function(x, mu, sigma) { p = (1/(x * sigma * sqrt(2 * pi))) * exp(-((log(x) - mu)/sigma)^2) return(p) } mu &lt;- 20 sigma &lt;- 12 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dlognorm(X, mu = mu, sigma = sigma), type = &quot;l&quot;, col = &quot;red&quot;) Hide Inverse Gaussian Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, \\mu&gt;0, z=\\frac{x-\\mu}{\\mu}~,~y=\\frac{x+\\mu}{\\mu} \\\\ \\hline \\small{\\text{Probability density}} &amp; \\Big(\\frac{\\theta}{2\\pi x^3}\\Big)^{1/2}\\exp\\Big(\\frac{-\\theta z^2}{2x}\\Big) \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\Phi\\Big[z\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big]+\\exp\\Big(\\frac{2\\theta}{\\mu}\\Big)\\Phi\\Big[-y\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big] \\\\ ~~F(x) &amp; \\\\ \\hline \\text{Mean} &amp; \\mu \\\\ \\mathrm{E}[X] &amp; \\\\ \\hline \\mathrm{Var[X]} &amp; \\frac{\\mu^3}{\\theta}\\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; x-\\mu x\\Phi\\Big[z\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big]-(\\mu y)\\exp\\Big(\\frac{2\\theta}{\\mu}\\Big)\\Phi\\Big[-y\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big] \\\\ &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dinvgauss}(x=, mean=\\mu,dispersion=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pinvgauss}(p=, mean=\\mu,dispersion=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qinvgauss}(q=, mean=\\mu,dispersion=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rinvgauss}(n=, mean=\\mu,dispersion=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph mu &lt;- 100 theta &lt;- 1000 X &lt;- seq(from = 0, to = 100, by = 1) plot(x = X, y = dinvgauss(X, mean = mu, dispersion = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Inverse Gaussian Distribution&quot;) 1.2.6 Distributions with Finite Support Beta Generalized Beta Hide Beta Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, ~a&gt;0,~b&gt;0, u=\\frac{x}{\\theta},~0&lt;x&lt;\\theta \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)} u^a(1-u)^{b-1}\\frac{1}{x} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\beta(a,b;u) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k \\Gamma(a+b)\\Gamma(a+k)}{\\Gamma(a)\\Gamma(a+b+k)} \\\\ ~~\\mathrm{E}[X^k] &amp; k&gt;-a \\\\ \\hline &amp; \\frac{\\theta^k a(a+1)\\cdots(a+k-1)}{(a+b)(a+b+1)\\cdots(a+b+k-1)}\\beta(a+k,b;u)+x^k[1-\\beta(a,b;u)] \\\\ ~~\\mathrm{E}[X\\wedge x]^k &amp; \\\\ \\hline \\end{array} \\end{matrix} \\] R Commands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dbeta}(x=, shape1=a,shape2=b,ncp=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pbeta}(p=, shape1=a,shape2=b,ncp=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qbeta}(q=, shape1=a,shape2=b,ncp=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rbeta}(n=, shape1=a,shape2=b,ncp=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] a &lt;- 2 b &lt;- 4 theta &lt;- 1 X &lt;- seq(from = 0, to = 1, by = 1e-04) plot(x = X, y = dbeta(X, shape1 = a, shape2 = b, ncp = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Beta Distribution&quot;) Hide Generalized Beta Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Name} &amp; \\text{Function} \\\\ \\hline \\small{\\text{Parameter assumptions}} &amp; \\theta&gt;0, a&gt;0, b&gt;0, \\tau&gt;0, 0&lt;x&lt;\\theta~,~u=(x/\\theta)^\\tau \\\\ \\hline \\small{\\text{Probability density}} &amp; \\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}u^\\alpha(1-u)^{b-1}\\frac{\\tau}{x} \\\\ ~~ \\small{\\text{function }} f(x)&amp; \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\beta(a,b;u) \\\\ ~~F(x) &amp; \\\\ \\hline \\textit{k}^{th}~\\small{\\text{raw moment}} &amp; \\frac{\\theta^k\\Gamma(a+b)\\Gamma(a+(k/\\tau))}{\\Gamma(a)\\Gamma(a+b+(k/\\tau))} \\\\ ~~\\mathrm{E}[X^k] &amp; k&gt;-\\alpha\\tau \\\\ \\hline \\mathrm{E}[(X\\wedge x)^k] &amp; \\frac{\\theta^k\\Gamma(a+b)\\Gamma(a+(k/\\tau))}{\\Gamma(a)\\Gamma(a+b+(k/\\tau))}\\beta(a+(k/\\tau),b;u)+x^k[1-\\beta(a,b;u)] \\\\ \\hline \\end{array} \\end{matrix} \\] R Commmands \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Function Name} &amp; \\text{R Command} \\\\ \\hline \\small{\\text{Density function}} &amp; \\text{dgenbeta}(x=, shape1=a,shape2=b,shape3=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Distribution function}} &amp; \\text{pgenbeta}(p=, shape1=a,shape2=b,shape3=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Quantile function}} &amp; \\text{qgenbeta}(q=, shape1=a,shape2=b,shape3=\\tau,scale=\\theta) \\\\ \\hline \\small{\\text{Random sampling function}} &amp; \\text{rgenbeta}(n=, shape1=a,shape2=b,shape3=\\tau,scale=\\theta) \\\\ \\hline \\end{array} \\end{matrix} \\] Illustrative Graph a &lt;- 3 b &lt;- 5 tau &lt;- 2 theta &lt;- 1000 X &lt;- seq(from = 0, to = 1000, by = 1) plot(x = X, y = dgenbeta(X, shape1 = a, shape2 = b, shape3 = tau, scale = theta), type = &quot;l&quot;, ylab = &quot;Probability density&quot;, col = &quot;red&quot;, main = &quot;Generalized Beta Distribution&quot;) 1.3 Limited Expected Values Overview. This section summarizes limited expected values for selected continuous distributions. Functions Graph Hide Functions Limited Expected Value Functions \\[ \\begin{matrix} \\begin{array}{l|c} \\hline \\text{Distribuion} &amp; \\text{Function} \\\\ \\hline \\text{GB2} &amp; \\frac{\\theta\\Gamma(\\tau+1)\\Gamma(\\alpha-1)}{\\Gamma(\\alpha)\\Gamma(\\tau)}\\beta(\\tau+1,\\alpha-1;\\frac{x}{x+\\beta})+x[1-\\beta(\\tau,\\alpha;\\frac{x}{x+\\beta})] \\\\ \\hline \\text{Burr} &amp; \\frac{\\theta\\Gamma(1+\\frac{1}{\\gamma})\\Gamma(\\alpha-\\frac{1}{\\gamma})}{\\Gamma(\\alpha)}\\beta(1+\\frac{1}{\\gamma},\\alpha-\\frac{1}{\\gamma};1-\\frac{1}{1+(x/\\theta)^\\gamma})+x\\Big(\\frac{1}{1+(x/\\theta)^\\gamma}\\Big)^\\alpha \\\\ \\hline \\text{Inverse Burr} &amp; \\frac{\\theta\\Gamma(\\tau+(1/\\gamma))\\Gamma(1-(1/\\gamma))}{\\Gamma(\\tau)}\\beta(\\tau+\\frac{1}{\\gamma},1-\\frac{1}{\\gamma};\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma})+x[1-\\Big(\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma}\\Big)^\\tau] \\\\ \\hline \\text{Pareto} &amp; \\\\ \\alpha=1 &amp; -\\theta \\ln \\Big(\\frac{\\theta}{x+\\theta}\\Big) \\\\ \\alpha\\neq1 &amp; \\frac{\\theta}{\\alpha-1}[1-\\Big(\\frac{\\theta}{x+\\theta}\\Big)^{\\alpha-1}] \\\\ \\hline \\text{Inverse Pareto} &amp; \\theta\\tau\\int^{x/(x+\\theta)}_0~y^\\tau(1-y)^{-1}dy+x[1-\\Big(\\frac{x}{x+\\theta}\\Big)^\\tau] \\\\ \\hline \\text{Loglogistic} &amp; \\theta\\Gamma(1+\\frac{1}{\\gamma})\\Gamma(1-\\frac{1}{\\gamma})\\beta(1+\\frac{1}{\\gamma},1-\\frac{1}{\\gamma};\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma})+x(1-\\frac{(x/\\theta)^\\gamma}{1+(x/\\theta)^\\gamma}) \\\\ \\hline \\text{Paralogistic} &amp; \\frac{\\theta\\Gamma(1+\\frac{1}{\\alpha})\\Gamma(\\alpha-\\frac{1}{\\alpha})}{\\Gamma(\\alpha)}\\beta(1+\\frac{1}{\\alpha},\\alpha-\\frac{1}{\\alpha};1-\\frac{1}{1+(x/\\theta)^\\alpha})+x\\Big(\\frac{1}{1+(x/\\theta)^\\alpha}\\Big)^\\alpha \\\\ \\hline \\text{Inverse Paralogistic} &amp; \\frac{\\theta\\Gamma(\\tau+\\frac{1}{\\tau})\\Gamma(1-\\frac{1}{\\tau})}{\\Gamma(\\tau)}\\beta(\\tau+\\frac{1}{\\tau},1-\\frac{1}{\\tau};\\frac{(x/\\theta)^\\tau}{1+(x/\\theta)^\\tau})+x[1-\\Big(\\frac{(x/\\theta)^\\tau}{1+(x/\\theta)^\\tau}\\Big)^\\tau] \\\\ \\hline \\text{Gamma} &amp; \\frac{\\theta\\Gamma(\\alpha+1)}{\\Gamma(\\alpha)}\\Gamma(\\alpha+1;\\frac{x}{\\theta})+x[1-\\Gamma(\\alpha;\\frac{x}{\\theta})] \\\\ \\hline \\text{Inverse Gamma} &amp; \\frac{\\theta\\Gamma(\\alpha-1)}{\\Gamma(\\alpha)}[1-\\Gamma(\\alpha-1;\\frac{\\theta}{x})]+x\\Gamma(\\alpha;\\frac{\\theta}{x}) \\\\ \\hline \\text{Weibull} &amp; \\theta\\Gamma(1+\\frac{1}{\\alpha})\\Gamma(1+\\frac{1}{\\alpha};\\Big(\\frac{x}{\\theta}\\Big)^\\alpha)+x*\\exp(-(x/\\theta)^\\alpha) \\\\ \\hline \\text{Inverse Weibull} &amp; \\theta\\Gamma(1-\\frac{1}{\\alpha})[1-\\Gamma(1-\\frac{1}{\\alpha};\\Big(\\frac{\\theta}{x}\\Big)^\\alpha)]+x[1-\\exp(-(\\theta/x)^\\alpha)] \\\\ \\hline \\text{Exponential} &amp; \\theta(1-\\exp(-(x/\\theta))) \\\\ \\hline \\text{Inverse Exponential} &amp; \\theta G(0;\\frac{\\theta}{x})+x(1-\\exp(-(\\theta/x))) \\\\ \\hline \\text{Lognormal} &amp; \\exp(\\mu+\\sigma^2/2)\\Phi\\Big(\\frac{\\ln (x)-\\mu-\\sigma^2}{\\sigma}\\Big)+x[1-\\Phi\\Big(\\frac{\\ln (x)-\\mu}{\\sigma}\\Big)] \\\\ \\hline \\text{Inverse Gaussian} &amp; x-\\mu\\Big(\\frac{x-\\mu}{\\mu}\\Big)\\Phi\\Big[\\Big(\\frac{x-\\mu}{\\mu}\\Big)\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big]-\\mu\\Big(\\frac{x+\\mu}{\\mu}\\Big)\\exp\\Big(\\frac{2\\theta}{\\mu}\\Big)\\Phi\\Big[-\\Big(\\frac{x+\\mu}{\\mu}\\Big)\\Big(\\frac{\\theta}{x}\\Big)^{1/2}\\Big] \\\\ \\hline \\text{Single-Parameter Pareto} &amp; \\frac{\\alpha\\theta}{\\alpha-1}-\\frac{\\theta^\\alpha}{(\\alpha-1)x^{\\alpha-1}} \\\\ \\hline \\text{Generalized Beta} &amp; \\frac{\\theta\\Gamma(a+b)\\Gamma(a+\\frac{1}{\\tau})}{\\Gamma(a)\\Gamma(a+b+\\frac{1}{\\tau})}\\beta(a+\\frac{1}{\\tau},b;\\Big(\\frac{x}{\\theta}\\Big)^\\tau)+x\\Big[1-\\beta(a,b;\\Big(\\frac{x}{\\theta}\\Big)^\\tau)\\Big] \\\\ \\hline \\text{Beta} &amp; \\frac{\\theta a}{(a+b)}\\beta(a+1,b;\\frac{x}{\\theta})+x[1-\\beta(a,b;\\frac{x}{\\theta})] \\\\ \\hline \\end{array} \\end{matrix} \\] Hide Illustrative Graph Comparison of Limited Expected Values for Selected Distributions \\[ \\begin{matrix} \\begin{array}{l|c|c|c|c|c|c} \\hline \\text{Distribution} &amp; \\text{Parameters} &amp; \\mathrm{E}[X] &amp; E[X\\wedge100] &amp; E[X\\wedge250] &amp; E[X\\wedge500] &amp;E[X\\wedge1000] \\\\ \\hline \\text{Pareto} &amp; \\alpha = 3, \\theta = 200 &amp; 100 &amp; 55.55 &amp;80.25 &amp; 91.84 &amp; 97.22 \\\\ \\hline \\text{Exponential} &amp; \\theta = 100 &amp; 100 &amp; 63.21 &amp; 91.79 &amp; 99.33 &amp; 99.99 \\\\ \\hline \\text{Gamma} &amp; \\alpha = 2, \\theta = 50 &amp; 100 &amp; 72.93 &amp; 97.64 &amp; 99.97 &amp; 100 \\\\ \\hline \\text{Weibull} &amp; \\tau=2, \\theta=\\frac{200}{\\sqrt[]{\\pi}} &amp; 100 &amp; 78.99 &amp; 99.82 &amp; 100 &amp; 100 \\\\ \\hline \\text{GB2} &amp; \\alpha = 3,\\tau=2,\\theta = 100 &amp; 100 &amp; 62.50 &amp; 86.00 &amp; 94.91 &amp; 98.42 \\\\ \\hline \\end{array} \\end{matrix} \\] "],["bibliography.html", "Bibliography", " Bibliography "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
