<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Appendix B: Iterated Expectations | Loss Data Analytics   Second Edition</title>
  <meta name="description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Appendix B: Iterated Expectations | Loss Data Analytics   Second Edition" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="github-repo" content="https://github.com/openacttexts/Loss-Data-Analytics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Appendix B: Iterated Expectations | Loss Data Analytics   Second Edition" />
  
  <meta name="twitter:description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

<meta name="author" content="An open text authored by the Actuarial Community" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="CAppA.html"/>
<link rel="next" href="CAppC.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<script>
function markdownConverterEWF() {  
//Create showdown markdown converter
var converter = new showdown.Converter();
converter.setOption('ghCompatibleHeaderId', true);
survey
    .onTextMarkdown
    .add(function (survey, options) {
        //convert the markdown text to html
        var str = converter.makeHtml(options.text);
        //remove root paragraphs <p></p>
        str = str.substring(3);
        str = str.substring(0, str.length - 4);
        //set html
        options.html = str;
        MathJax.Hub.Queue(['Typeset',MathJax.Hub, 'options']);
    });  
};

// Quiz Header info
const jsonHeader = { 
    showProgressBar: "bottom",
    showTimerPanel: "none",
    maxTimeToFinishPage: 10000,
    maxTimeToFinish: 25000,
    firstPageIsStarted: true,
    startSurveyText: "Start Quiz" //,
//    title: "Does This Make Sense?"
}


// One and Two question quizzes
function jsonSummary1EWF(json) {  
let jsonEnd1 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
};  
return jsonEnd1;
};


function jsonSummary2EWF(json) {  
let jsonEnd2 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][2]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][2]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][2]["questions"][0]["correctAnswer"]
};  
return jsonEnd2;
};

// Three, four, and five question quizzes
function jsonSummary3EWF(json) {  
let jsonEnd3 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][2]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][2]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][2]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][3]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][3]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][3]["questions"][0]["correctAnswer"]
};  
return jsonEnd3;
};

function jsonSummary4EWF(json) {  
jsonEnd4 = jsonSummary3EWF(json);
jsonEnd4.completedHtml = jsonEnd4.completedHtml +  
"<br>"+
json["pages"][4]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][4]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][4]["questions"][0]["correctAnswer"]
;  
return jsonEnd4;
};

function jsonSummary5EWF(json) {  
jsonEnd5 = jsonSummary4EWF(json);
jsonEnd5.completedHtml = jsonEnd5.completedHtml +  
"<br>"+
json["pages"][5]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][5]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][5]["questions"][0]["correctAnswer"]
;  
return jsonEnd5;
};

function jsonSummary6EWF(json) {  
jsonEnd6 = jsonSummary5EWF(json);
jsonEnd6.completedHtml = jsonEnd6.completedHtml +  
"<br>"+
json["pages"][6]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][6]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][6]["questions"][0]["correctAnswer"]
;  
return jsonEnd6;
};

function jsonSummary7EWF(json) {  
jsonEnd7 = jsonSummary6EWF(json);
jsonEnd7.completedHtml = jsonEnd7.completedHtml +  
"<br>"+
json["pages"][7]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][7]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][7]["questions"][0]["correctAnswer"]
;  
return jsonEnd7;
};

function jsonSummary8EWF(json) {  
jsonEnd8 = jsonSummary7EWF(json);
jsonEnd8.completedHtml = jsonEnd8.completedHtml +  
"<br>"+
json["pages"][8]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][8]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][8]["questions"][0]["correctAnswer"]
;  
return jsonEnd8;
};

function jsonSummary9EWF(json) {  
jsonEnd9 = jsonSummary8EWF(json);
jsonEnd9.completedHtml = jsonEnd9.completedHtml +  
"<br>"+
json["pages"][9]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][9]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][9]["questions"][0]["correctAnswer"]
;  
return jsonEnd9;
};


function jsonSummary10EWF(json) {  
jsonEnd10 = jsonSummary9EWF(json);
jsonEnd10.completedHtml = jsonEnd10.completedHtml +  
"<br>"+
json["pages"][10]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][10]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][10]["questions"][0]["correctAnswer"]
;  
return jsonEnd10;
};


function jsonSummary11EWF(json) {  
jsonEnd11 = jsonSummary10EWF(json);
jsonEnd11.completedHtml = jsonEnd11.completedHtml +  
"<br>"+
json["pages"][11]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][11]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][11]["questions"][0]["correctAnswer"]
;  
return jsonEnd11;
};

Survey.StylesManager.applyTheme("modern");

</script>  
<!-- This completes the code for the quizzes -->

<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>

<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  if (t = document.getElementById("webex-total_correct")) {
    var correct = document.getElementsByClassName("webex-correct").length;
    var solvemes = document.getElementsByClassName("webex-solveme").length;
    var radiogroups = document.getElementsByClassName("webex-radiogroup").length;
    var selects = document.getElementsByClassName("webex-select").length;
    
    t.innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");
  
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");
  
  var cl = this.classList
  
  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;
  
  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }
  
  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

window.onload = function() {
  console.log("onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }
  
  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }
  
  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
  }

  update_total_correct();
}

</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="Format/style.css" type="text/css" />
<link rel="stylesheet" href="includeWebex/webex.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Loss Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i>Contributors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#reviewers"><i class="fa fa-check"></i>Reviewers</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#other-collaborators"><i class="fa fa-check"></i>Other Collaborators</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-number"><i class="fa fa-check"></i>Version Number</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#for-our-readers"><i class="fa fa-check"></i>For our Readers</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="CAppA.html"><a href="CAppA.html"><i class="fa fa-check"></i><b>1</b> Appendix A: Review of Statistical Inference</a>
<ul>
<li class="chapter" data-level="1.1" data-path="CAppA.html"><a href="CAppA.html#S:Sec171"><i class="fa fa-check"></i><b>1.1</b> Basic Concepts</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="CAppA.html"><a href="CAppA.html#random-sampling"><i class="fa fa-check"></i><b>1.1.1</b> Random Sampling</a></li>
<li class="chapter" data-level="1.1.2" data-path="CAppA.html"><a href="CAppA.html#sampling-distribution"><i class="fa fa-check"></i><b>1.1.2</b> Sampling Distribution</a></li>
<li class="chapter" data-level="1.1.3" data-path="CAppA.html"><a href="CAppA.html#central-limit-theorem"><i class="fa fa-check"></i><b>1.1.3</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="CAppA.html"><a href="CAppA.html#S:Sec172"><i class="fa fa-check"></i><b>1.2</b> Point Estimation and Properties</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="CAppA.html"><a href="CAppA.html#method-of-moments-estimation"><i class="fa fa-check"></i><b>1.2.1</b> Method of Moments Estimation</a></li>
<li class="chapter" data-level="1.2.2" data-path="CAppA.html"><a href="CAppA.html#S:Sec1722"><i class="fa fa-check"></i><b>1.2.2</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="CAppA.html"><a href="CAppA.html#S:Sec173"><i class="fa fa-check"></i><b>1.3</b> Interval Estimation</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="CAppA.html"><a href="CAppA.html#S:Sec1731"><i class="fa fa-check"></i><b>1.3.1</b> Exact Distribution for Normal Sample Mean</a></li>
<li class="chapter" data-level="1.3.2" data-path="CAppA.html"><a href="CAppA.html#large-sample-properties-of-mle"><i class="fa fa-check"></i><b>1.3.2</b> Large-sample Properties of <em>MLE</em></a></li>
<li class="chapter" data-level="1.3.3" data-path="CAppA.html"><a href="CAppA.html#confidence-interval"><i class="fa fa-check"></i><b>1.3.3</b> Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="CAppA.html"><a href="CAppA.html#S:Sec174"><i class="fa fa-check"></i><b>1.4</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="CAppA.html"><a href="CAppA.html#basic-concepts"><i class="fa fa-check"></i><b>1.4.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="1.4.2" data-path="CAppA.html"><a href="CAppA.html#student-t-test-based-on-mle"><i class="fa fa-check"></i><b>1.4.2</b> Student-<em>t</em> test based on <em>mle</em></a></li>
<li class="chapter" data-level="1.4.3" data-path="CAppA.html"><a href="CAppA.html#S:Sec1743"><i class="fa fa-check"></i><b>1.4.3</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="1.4.4" data-path="CAppA.html"><a href="CAppA.html#S:Sec1744"><i class="fa fa-check"></i><b>1.4.4</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="CAppB.html"><a href="CAppB.html"><i class="fa fa-check"></i><b>2</b> Appendix B: Iterated Expectations</a>
<ul>
<li class="chapter" data-level="2.1" data-path="CAppB.html"><a href="CAppB.html#S:AppB:CD"><i class="fa fa-check"></i><b>2.1</b> Conditional Distribution and Conditional Expectation</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="CAppB.html"><a href="CAppB.html#conditional-distribution"><i class="fa fa-check"></i><b>2.1.1</b> Conditional Distribution</a></li>
<li class="chapter" data-level="2.1.2" data-path="CAppB.html"><a href="CAppB.html#conditional-expectation-and-conditional-variance"><i class="fa fa-check"></i><b>2.1.2</b> Conditional Expectation and Conditional Variance</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="CAppB.html"><a href="CAppB.html#S:AppB:IE"><i class="fa fa-check"></i><b>2.2</b> Iterated Expectations and Total Variance</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="CAppB.html"><a href="CAppB.html#S:AppB:LIE"><i class="fa fa-check"></i><b>2.2.1</b> Law of Iterated Expectations</a></li>
<li class="chapter" data-level="2.2.2" data-path="CAppB.html"><a href="CAppB.html#law-of-total-variance"><i class="fa fa-check"></i><b>2.2.2</b> Law of Total Variance</a></li>
<li class="chapter" data-level="2.2.3" data-path="CAppB.html"><a href="CAppB.html#application"><i class="fa fa-check"></i><b>2.2.3</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="CAppB.html"><a href="CAppB.html#S:AppConjugateDistributions"><i class="fa fa-check"></i><b>2.3</b> Conjugate Distributions</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="CAppB.html"><a href="CAppB.html#linear-exponential-family"><i class="fa fa-check"></i><b>2.3.1</b> Linear Exponential Family</a></li>
<li class="chapter" data-level="2.3.2" data-path="CAppB.html"><a href="CAppB.html#S:IterExp:Conjugate"><i class="fa fa-check"></i><b>2.3.2</b> Conjugate Distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="CAppC.html"><a href="CAppC.html"><i class="fa fa-check"></i><b>3</b> Appendix C: Maximum Likelihood Theory</a>
<ul>
<li class="chapter" data-level="3.1" data-path="CAppC.html"><a href="CAppC.html#S:Sec191"><i class="fa fa-check"></i><b>3.1</b> Likelihood Function</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="CAppC.html"><a href="CAppC.html#likelihood-and-log-likelihood-functions"><i class="fa fa-check"></i><b>3.1.1</b> Likelihood and Log-likelihood Functions</a></li>
<li class="chapter" data-level="3.1.2" data-path="CAppC.html"><a href="CAppC.html#properties-of-likelihood-functions"><i class="fa fa-check"></i><b>3.1.2</b> Properties of Likelihood Functions</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="CAppC.html"><a href="CAppC.html#S:Sec192"><i class="fa fa-check"></i><b>3.2</b> Maximum Likelihood Estimators</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="CAppC.html"><a href="CAppC.html#definition-and-derivation-of-mle"><i class="fa fa-check"></i><b>3.2.1</b> Definition and Derivation of <em>MLE</em></a></li>
<li class="chapter" data-level="3.2.2" data-path="CAppC.html"><a href="CAppC.html#asymptotic-properties-of-mle"><i class="fa fa-check"></i><b>3.2.2</b> Asymptotic Properties of <em>MLE</em></a></li>
<li class="chapter" data-level="3.2.3" data-path="CAppC.html"><a href="CAppC.html#use-of-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>3.2.3</b> Use of Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="CAppC.html"><a href="CAppC.html#S:Sec193"><i class="fa fa-check"></i><b>3.3</b> Statistical Inference Based on Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="CAppC.html"><a href="CAppC.html#hypothesis-testing"><i class="fa fa-check"></i><b>3.3.1</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="3.3.2" data-path="CAppC.html"><a href="CAppC.html#S:Sec1932"><i class="fa fa-check"></i><b>3.3.2</b> <em>MLE</em> and Model Validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html"><i class="fa fa-check"></i><b>4</b> Appendix D: Summary of Distributions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#S:DiscreteDistributions"><i class="fa fa-check"></i><b>4.1</b> Discrete Distributions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#the-ab0-class"><i class="fa fa-check"></i><b>4.1.1</b> The <em>(a,b,0)</em> Class</a></li>
<li class="chapter" data-level="4.1.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#the-ab1-class"><i class="fa fa-check"></i><b>4.1.2</b> The <em>(a,b,1)</em> Class</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#S:ContinuousDistributions"><i class="fa fa-check"></i><b>4.2</b> Continuous Distributions</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#one-parameter-distributions"><i class="fa fa-check"></i><b>4.2.1</b> One Parameter Distributions</a></li>
<li class="chapter" data-level="4.2.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#two-parameter-distributions"><i class="fa fa-check"></i><b>4.2.2</b> Two Parameter Distributions</a></li>
<li class="chapter" data-level="4.2.3" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#three-parameter-distributions"><i class="fa fa-check"></i><b>4.2.3</b> Three Parameter Distributions</a></li>
<li class="chapter" data-level="4.2.4" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#four-parameter-distribution"><i class="fa fa-check"></i><b>4.2.4</b> Four Parameter Distribution</a></li>
<li class="chapter" data-level="4.2.5" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#other-distributions"><i class="fa fa-check"></i><b>4.2.5</b> Other Distributions</a></li>
<li class="chapter" data-level="4.2.6" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#distributions-with-finite-support"><i class="fa fa-check"></i><b>4.2.6</b> Distributions with Finite Support</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#limited-expected-values"><i class="fa fa-check"></i><b>4.3</b> Limited Expected Values</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html"><i class="fa fa-check"></i><b>5</b> Appendix E: Conventions for Notation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:General"><i class="fa fa-check"></i><b>5.1</b> General Conventions</a></li>
<li class="chapter" data-level="5.2" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:Abbreviations"><i class="fa fa-check"></i><b>5.2</b> Abbreviations</a></li>
<li class="chapter" data-level="5.3" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:StatSymbols"><i class="fa fa-check"></i><b>5.3</b> Common Statistical Symbols and Operators</a></li>
<li class="chapter" data-level="5.4" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:Symbols"><i class="fa fa-check"></i><b>5.4</b> Common Mathematical Symbols and Functions</a></li>
<li class="chapter" data-level="5.5" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#further-readings"><i class="fa fa-check"></i><b>5.5</b> Further Readings</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTexts/Loss-Data-Analytics" target="blank">Loss Data Analytics on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loss Data Analytics <br> Second Edition</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="CAppB" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Appendix B: Iterated Expectations<a href="CAppB.html#CAppB" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This appendix introduces the laws related to iterated expectations. In particular, Section <a href="CAppB.html#S:AppB:CD">2.1</a> introduces the concepts of conditional distribution and conditional expectation. Section <a href="CAppB.html#S:AppB:IE">2.2</a> introduces the Law of Iterated Expectations and the Law of Total Variance.</p>
<p>In some situations, we only observe a single outcome but can conceptualize an outcome as resulting from a two (or more) stage process. Such types of statistical models are called <strong>two-stage</strong>, or <strong>hierarchical</strong> models. Some special cases of hierarchical models include:</p>
<ul>
<li>models where the parameters of the distribution are random variables;</li>
<li>mixture distribution, where Stage 1 represents the draw of a subpopulation and Stage 2 represents a random variable from a distribution that is determined by the subpopulation drew in Stage 1;</li>
<li>an aggregate distribution, where Stage 1 represents the draw of the number of events and Stage 2 represents the loss amount occurred per event.</li>
</ul>
<p>In these situations, the process gives rise to a conditional distribution of a random variable (the Stage 2 outcome) given the other (the Stage 1 outcome). The Law of Iterated Expectations can be useful for obtaining the unconditional expectation or variance of a random variable in such cases.</p>
<div id="S:AppB:CD" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Conditional Distribution and Conditional Expectation<a href="CAppB.html#S:AppB:CD" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn</p>
<ul>
<li>the concepts related to the conditional distribution of a random variable given another</li>
<li>how to define the conditional expectation and variance based on the conditional distribution function</li>
</ul>
<hr />
<p>The iterated expectations are the laws regarding calculation of the expectation and variance of a random variable using a conditional distribution of the variable given another variable. Hence, we first introduce the concepts related to the conditional distribution, and the calculation of the conditional expectation and variance based on a given conditional distribution.</p>
<div id="conditional-distribution" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Conditional Distribution<a href="CAppB.html#conditional-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Here we introduce the concept of conditional distribution respectively for discrete and continuous random variables.</p>
<div id="discrete-case" class="section level4 hasAnchor" number="2.1.1.1">
<h4><span class="header-section-number">2.1.1.1</span> Discrete Case<a href="CAppB.html#discrete-case" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Suppose that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are both discrete random variables, meaning that they can take a finite or countable number of possible values with a positive probability. The <strong>joint probability (mass) function</strong> of (<span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>) is defined as</p>
<p><span class="math display">\[
p(x,y) = \Pr[X=x, Y=y] .
\]</span></p>
<p>When <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <strong>independent</strong> (the value of <span class="math inline">\(X\)</span> does not depend on that of <span class="math inline">\(Y\)</span>), we have</p>
<p><span class="math display">\[
p(x,y)=p(x)p(y),
\]</span></p>
<p>with <span class="math inline">\(p(x)=\Pr[X=x]\)</span> and <span class="math inline">\(p(y)=\Pr[Y=y]\)</span> being the <strong>marginal probability functions</strong> of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, respectively.</p>
<p>Given the joint probability function, we may obtain the marginal probability function of <span class="math inline">\(Y\)</span> as</p>
<p><span class="math display">\[
p(y)=\sum_x p(x,y),
\]</span></p>
<p>where the summation is over all possible values of <span class="math inline">\(x\)</span>, and the marginal probability function of <span class="math inline">\(X\)</span> can be obtained in a similar manner.</p>
<p>The <strong>conditional probability (mass) function</strong> of <span class="math inline">\((Y|X)\)</span> is defined as</p>
<p><span class="math display">\[
p(y|x) =\Pr[Y=y|X=x]= \frac{p(x,y)}{\Pr[X=x]},
\]</span></p>
<p>where we may obtain the conditional probability function of <span class="math inline">\((X|Y)\)</span> in a similar manner. In particular, the above conditional probability represents the probability of the event <span class="math inline">\(Y=y\)</span> given the event <span class="math inline">\(X=x\)</span>. Hence, even in cases where <span class="math inline">\(\Pr[X=x]=0\)</span>, the function may be given as a particular form, in real applications.</p>
</div>
<div id="continuous-case" class="section level4 hasAnchor" number="2.1.1.2">
<h4><span class="header-section-number">2.1.1.2</span> Continuous Case<a href="CAppB.html#continuous-case" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For continuous random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, we may define their joint probability (density) function based on the joint cumulative distribution function. The <strong>joint cumulative distribution function</strong> of (<span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>) is defined as</p>
<p><span class="math display">\[
F(x,y) = \Pr[X\leq x, Y\leq y].
\]</span></p>
<p>When <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <em>independent</em>, we have</p>
<p><span class="math display">\[
F(x,y)=F(x)F(y),
\]</span></p>
<p>with <span class="math inline">\(F(x)=\Pr[X\leq x]\)</span> and <span class="math inline">\(F(y)=\Pr[Y\leq y]\)</span> being the <strong>cumulative distribution functions</strong> (cdfs) of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, respectively. The random variable <span class="math inline">\(X\)</span> is referred to as a <strong>continuous</strong> random variable if its cdf is continuous on <span class="math inline">\(x\)</span>.</p>
<p>When the cdf <span class="math inline">\(F(x)\)</span> is continuous on <span class="math inline">\(x\)</span>, then we define <span class="math inline">\(f(x)=\partial F(x)/\partial x\)</span> as the <strong>(marginal) probability density function</strong> (pdf) of <span class="math inline">\(X\)</span>. Similarly, if the joint cdf <span class="math inline">\(F(x,y)\)</span> is continuous on both <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, we define</p>
<p><span class="math display">\[
f(x,y)=\frac{\partial^2 F(x,y)}{\partial x\partial y}
\]</span></p>
<p>as the <strong>joint probability density function</strong> of (<span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>), in which case we refer to the random variables as <strong>jointly continuous</strong>.</p>
<p>When <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <em>independent</em>, we have</p>
<p><span class="math display">\[
f(x,y)=f(x)f(y).
\]</span></p>
<p>Given the joint density function, we may obtain the marginal density function of <span class="math inline">\(Y\)</span> as</p>
<p><span class="math display">\[
f(y)=\int_x f(x,y)\,dx,
\]</span></p>
<p>where the integral is over all possible values of <span class="math inline">\(x\)</span>, and the marginal probability function of <span class="math inline">\(X\)</span> can be obtained in a similar manner.</p>
<p>Based on the joint <a href="#" class="tooltip" style="color:green"><em>pdf</em><span style="font-size:8pt">Probability density function</span></a> and the marginal pdf, we define the <strong>conditional probability density function</strong> of <span class="math inline">\((Y|X)\)</span> as</p>
<p><span class="math display">\[
f(y|x) = \frac{f(x,y)}{f(x)},
\]</span></p>
<p>where we may obtain the conditional probability function of <span class="math inline">\((X|Y)\)</span> in a similar manner. Here, the conditional density function is the density function of <span class="math inline">\(y\)</span> given <span class="math inline">\(X=x\)</span>. Hence, even in cases where <span class="math inline">\(\Pr[X=x]=0\)</span> or when <span class="math inline">\(f(x)\)</span> is not defined, the function may be given in a particular form in real applications.</p>
</div>
</div>
<div id="conditional-expectation-and-conditional-variance" class="section level3 hasAnchor" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Conditional Expectation and Conditional Variance<a href="CAppB.html#conditional-expectation-and-conditional-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now we define the conditional expectation and variance based on the conditional distribution defined in the previous subsection.</p>
<div id="discrete-case-1" class="section level4 hasAnchor" number="2.1.2.1">
<h4><span class="header-section-number">2.1.2.1</span> Discrete Case<a href="CAppB.html#discrete-case-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For a discrete random variable <span class="math inline">\(Y\)</span>, its <strong>expectation</strong> is defined as <span class="math inline">\(\mathrm{E}[Y]=\sum_y y\,p(y)\)</span> if its value is finite, and its <strong>variance</strong> is defined as <span class="math inline">\(\mathrm{Var}[Y]=\mathrm{E}\{(Y-\mathrm{E}[Y])^2\}=\sum_y y^2\,p(y)-\{\mathrm{E}[Y]\}^2\)</span> if its value is finite.</p>
<p>For a discrete random variable <span class="math inline">\(Y\)</span>, the <strong>conditional expectation</strong> of the random variable <span class="math inline">\(Y\)</span> given the event <span class="math inline">\(X=x\)</span> is defined as</p>
<p><span class="math display">\[
\mathrm{E}[Y|X=x]=\sum_y y\,p(y|x),
\]</span></p>
<p>where <span class="math inline">\(X\)</span> does not have to be a discrete variable, as far as the conditional probability function <span class="math inline">\(p(y|x)\)</span> is given.</p>
<p>Note that the conditional expectation <span class="math inline">\(\mathrm{E}[Y|X=x]\)</span> is a fixed number. When we replace <span class="math inline">\(x\)</span> with <span class="math inline">\(X\)</span> on the right-hand side of the above equation, we can define the expectation of <span class="math inline">\(Y\)</span> given the random variable <span class="math inline">\(X\)</span> as</p>
<p><span class="math display">\[
\mathrm{E}[Y|X]=\sum_y y\,p(y|X),
\]</span></p>
<p>which is still a <em>random variable</em>, and the randomness comes from <span class="math inline">\(X\)</span>.</p>
<p>In a similar manner, we can define the <strong>conditional variance</strong> of the random variable <span class="math inline">\(Y\)</span> given the event <span class="math inline">\(X=x\)</span> as</p>
<p><span class="math display">\[
\mathrm{Var}[Y|X=x]=\mathrm{E}[Y^2|X=x]-\{\mathrm{E}[Y|X=x]\}^2=\sum_y y^2\,p(y|x)-\{\mathrm{E}[Y|X=x]\}^2.
\]</span></p>
<p>The variance of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>, <span class="math inline">\(\mathrm{Var}[Y|X]\)</span> can be defined by replacing <span class="math inline">\(x\)</span> by <span class="math inline">\(X\)</span> in the above equation, and <span class="math inline">\(\mathrm{Var}[Y|X]\)</span> is still a random variable and the randomness comes from <span class="math inline">\(X\)</span>.</p>
</div>
<div id="continuous-case-1" class="section level4 hasAnchor" number="2.1.2.2">
<h4><span class="header-section-number">2.1.2.2</span> Continuous Case<a href="CAppB.html#continuous-case-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For a continuous random variable <span class="math inline">\(Y\)</span>, its <strong>expectation</strong> is defined as <span class="math inline">\(\mathrm{E}[Y]=\int_y y\,f(y)dy\)</span> if the integral exists, and its <strong>variance</strong> is defined as <span class="math inline">\(\mathrm{Var}[Y]=\mathrm{E}\{(X-\mathrm{E}[Y])^2\}=\int_y y^2\,f(y)dy-\{\mathrm{E}[Y]\}^2\)</span> if its value is finite.</p>
<p>For jointly continuous random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, the <strong>conditional expectation</strong> of the random variable <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=x\)</span> is defined as
<span class="math display">\[\mathrm{E}[Y|X=x]=\int_y y\,f(y|x)dy.\]</span>
where <span class="math inline">\(X\)</span> does not have to be a continuous variable, as far as the conditional probability function <span class="math inline">\(f(y|x)\)</span> is given.</p>
<p>Similarly, the conditional expectation <span class="math inline">\(\mathrm{E}[Y|X=x]\)</span> is a fixed number. When we replace <span class="math inline">\(x\)</span> with <span class="math inline">\(X\)</span> on the right-hand side of the above equation, we can define the expectation of <span class="math inline">\(Y\)</span> given the random variable <span class="math inline">\(X\)</span> as</p>
<p><span class="math display">\[
\mathrm{E}[Y|X]=\int_y y\,p(y|X)\,dy,
\]</span></p>
<p>which is still a <em>random variable</em>, and the randomness comes from <span class="math inline">\(X\)</span>.</p>
<p>In a similar manner, we can define the <strong>conditional variance</strong> of the random variable <span class="math inline">\(Y\)</span> given the event <span class="math inline">\(X=x\)</span> as</p>
<p><span class="math display">\[
\mathrm{Var}[Y|X=x]=\mathrm{E}[Y^2|X=x]-\{\mathrm{E}[Y|X=x]\}^2=\int_y y^2\,f(y|x)\,dy-\{\mathrm{E}[Y|X=x]\}^2.
\]</span></p>
<p>The variance of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span>, <span class="math inline">\(\mathrm{Var}[Y|X]\)</span> can then be defined by replacing <span class="math inline">\(x\)</span> by <span class="math inline">\(X\)</span> in the above equation, and similarly <span class="math inline">\(\mathrm{Var}[Y|X]\)</span> is also a random variable and the randomness comes from <span class="math inline">\(X\)</span>.</p>
</div>
</div>
</div>
<div id="S:AppB:IE" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Iterated Expectations and Total Variance<a href="CAppB.html#S:AppB:IE" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn</p>
<ul>
<li>the Law of Iterated Expectations for calculating the expectation of a random variable based on its conditional distribution given another random variable</li>
<li>the Law of Total Variance for calculating the variance of a random variable based on its conditional distribution given another random variable</li>
<li>how to calculate the expectation and variance based on an example of a two-stage model</li>
</ul>
<hr />
<div id="S:AppB:LIE" class="section level3 hasAnchor" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Law of Iterated Expectations<a href="CAppB.html#S:AppB:LIE" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, and <span class="math inline">\(h(X,Y)\)</span>, a random variable depending on the function <span class="math inline">\(h\)</span>, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p>Assuming all the expectations exist and are finite, the <strong>Law of Iterated Expectations</strong> states that</p>
<p><span class="math display" id="eq:LawIterExp">\[\begin{equation}
\mathrm{E}[h(X,Y)]= \mathrm{E} \left\{ \mathrm{E} \left[ h(X,Y) | X \right] \right \},
\tag{2.1}
\end{equation}\]</span></p>
<p>where the first (inside) expectation is taken with respect to the random variable <span class="math inline">\(Y\)</span> and the second (outside) expectation is taken with respect to <span class="math inline">\(X\)</span>.</p>
<p>For the Law of Iterated Expectations, the random variables may be discrete, continuous, or a hybrid combination of the two. We use the example of discrete variables of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> to illustrate the calculation of the unconditional expectation using the Law of Iterated Expectations. For continuous random variables, we only need to replace the summation with the integral, as illustrated earlier in the appendix.</p>
<p>Given <span class="math inline">\(p(y|x)\)</span> the conditional <a href="#" class="tooltip" style="color:green"><em>pmf</em><span style="font-size:8pt">Probability mass function</span></a> of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, the conditional expectation of <span class="math inline">\(h(X,Y)\)</span> given the event <span class="math inline">\(X=x\)</span> is defined as</p>
<p><span class="math display">\[
\mathrm{E} \left[ h(X,Y) | X=x \right] = \sum_y h(x,y) p(y|x),
\]</span></p>
<p>and the conditional expectation of <span class="math inline">\(h(X,Y)\)</span> given <span class="math inline">\(X\)</span> being a <em>random variable</em> can be written as</p>
<p><span class="math display">\[
\mathrm{E} \left[ h(X,Y) | X \right] = \sum_y h(X,y) p(y|X).
\]</span></p>
<p>The unconditional expectation of <span class="math inline">\(h(X,Y)\)</span> can then be obtained by taking the expectation of <span class="math inline">\(\mathrm{E} \left[ h(X,Y) | X \right]\)</span> with respect to the random variable <span class="math inline">\(X\)</span>. That is, we can obtain <span class="math inline">\(\mathrm{E}[ h(X,Y)]\)</span> as</p>
<p><span class="math display">\[
\begin{aligned}
     \mathrm{E} \left\{ \mathrm{E} \left[ h(X,Y) | X \right] \right \}
    &amp;= \sum_x  \left\{\sum_y h(x,y) p(y|x) \right \} p(x) \\
    &amp;= \sum_x  \sum_y h(x,y) p(y|x)p(x) \\
    &amp;=  \sum_x  \sum_y h(x,y) p(x,y)
    =  \mathrm{E}[h(X,Y)] \end{aligned}.
\]</span></p>
<p>The Law of Iterated Expectations for the continuous and hybrid cases can be proved in a similar manner, by replacing the corresponding summation(s) by integral(s).</p>
</div>
<div id="law-of-total-variance" class="section level3 hasAnchor" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Law of Total Variance<a href="CAppB.html#law-of-total-variance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Assuming that all the variances exist and are finite, the <strong>Law of Total Variance</strong> states that</p>
<p><span class="math display" id="eq:LawTotVar">\[\begin{equation}
\mathrm{Var}[h(X,Y)]= \mathrm{E} \left\{ \mathrm{Var} \left[h(X,Y) | X \right] \right \}
    +\mathrm{Var} \left\{ \mathrm{E} \left[ h(X,Y) | X \right] \right \},
\tag{2.2}
\end{equation}\]</span></p>
<p>where the first (inside) expectation/variance is taken with respect to the random variable <span class="math inline">\(Y\)</span> and the second (outside) expectation/variance is taken with respect to <span class="math inline">\(X\)</span>. Thus, the unconditional variance equals to the expectation of the conditional variance plus the variance of the conditional expectation.</p>
<hr />
<h5 style="text-align: center;">
<a id="displayTheory.LTV.1" href="javascript:toggleTheory('toggleTheory.LTV.1','displayCode.LTV.1');"><i><strong>Show Verification of the Law of Total Variance</strong></i></a>
</h5>
<div id="toggleTheory.LTV.1" style="display: none">
<p>In order to verify this rule, first note that we can calculate a conditional variance as</p>
<p><span class="math display">\[
\mathrm{Var} \left[ h(X,Y) | X \right]  = \mathrm{E} [ h(X,Y)^2 | X ] -\left\{\mathrm{E} \left[ h(X,Y) | X \right] \right\}^2.
\]</span></p>
<p>From this, the expectation of the conditional variance is</p>
<p><span class="math display" id="eq:AppBEV1">\[\begin{align}
    \mathrm{E}\{\mathrm{Var} \left[ h(X,Y) | X \right] \} &amp;=
    \mathrm{E}\left\{\mathrm{E} \left[ h(X,Y)^2 | X \right] \right\} - \mathrm{E}\left(\left\{\mathrm{E} \left[ h(X,Y) | X \right] \right\}^2\right) \notag \\
    &amp;=\mathrm{E} \left[ h(X,Y)^2\right] - \mathrm{E}\left(\left\{\mathrm{E} \left[ h(X,Y) | X \right] \right\}^2\right).
\tag{2.3}
\end{align}\]</span></p>
<p>Further, note that the conditional expectation, <span class="math inline">\(\mathrm{E} \left[ h(X,Y) | X \right]\)</span>, is a function of <span class="math inline">\(X\)</span>, denoted <span class="math inline">\(g(X)\)</span>. Thus, <span class="math inline">\(g(X)\)</span> is a random variable with mean <span class="math inline">\(\mathrm{E}[h(X,Y)]\)</span> and variance</p>
<p><span class="math display" id="eq:AppBVE2">\[\begin{align}
    \mathrm{Var} \left\{ \mathrm{E} \left[ h(X,Y) | X \right] \right \} &amp;=\mathrm{Var}[g(X)]  \notag \\
    &amp;= \mathrm{E}[g(X)^2]\ - \left\{\mathrm{E}[g(X)]\right\}^2 \nonumber\\
    &amp;= \mathrm{E}\left(\left\{\mathrm{E} \left[ h(X,Y) | X \right] \right\}^2\right)
    - \left\{\mathrm{E}[h(X,Y)]\right\}^2.
\tag{2.4}
\end{align}\]</span></p>
<p>Thus, adding Equations <a href="CAppB.html#eq:AppBEV1">(2.3)</a> and <a href="CAppB.html#eq:AppBVE2">(2.4)</a> leads to the unconditional variance <span class="math inline">\(\mathrm{Var} \left[ h(X,Y) \right]\)</span>.</p>
</div>
<hr />
</div>
<div id="application" class="section level3 hasAnchor" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Application<a href="CAppB.html#application" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To apply the Law of Iterated Expectations and the Law of Total Variance, we generally adopt the following procedure.</p>
<ol style="list-style-type: decimal">
<li>Identify the random variable that is being conditioned upon, typically a stage 1 outcome (that is not observed).</li>
<li>Conditional on the stage 1 outcome, calculate summary measures such as a mean, variance, and the like.</li>
<li>There are several results of the step 2, one for each stage 1 outcome. Then, combine these results using the iterated
expectations or total variance rules.</li>
</ol>
<p><strong>Mixtures of Finite Populations.</strong> Suppose that the random variable <span class="math inline">\(N_1\)</span> represents a realization of the number of claims in a policy year from the population of good drivers and <span class="math inline">\(N_2\)</span> represents that from the population of bad drivers. For a specific driver, there is a probability <span class="math inline">\(\alpha\)</span> that (s)he is a good driver. For a specific draw <span class="math inline">\(N\)</span>, we have</p>
<p><span class="math display">\[
N =
    \begin{cases}
    N_1,  &amp;  \text{if (s)he is a good driver;}\\
    N_2,  &amp;   \text{otherwise}.\\
    \end{cases}
\]</span></p>
<p>Let <span class="math inline">\(T\)</span> be the indicator whether (s)he is a good driver, with <span class="math inline">\(T=1\)</span> representing that the driver is a good driver with <span class="math inline">\(\Pr[T=1]=\alpha\)</span> and <span class="math inline">\(T=2\)</span> representing that the driver is a bad driver with <span class="math inline">\(\Pr[T=2]=1-\alpha\)</span>.</p>
<p>From equation <a href="CAppB.html#eq:LawIterExp">(2.1)</a>, we can obtain the expected number of claims as <span class="math display">\[
    \mathrm{E}[N]= \mathrm{E} \left\{ \mathrm{E} \left[ N | T \right] \right \}= \mathrm{E}[N_1] \times \alpha +  \mathrm{E}[N_2] \times (1-\alpha).\]</span></p>
<p>From equation <a href="CAppB.html#eq:LawTotVar">(2.2)</a>, we can obtain the variance of <span class="math inline">\(N\)</span> as</p>
<p><span class="math display">\[
\mathrm{Var}[N]= \mathrm{E} \left\{ \mathrm{Var} \left[ N | T \right] \right \}
    +\mathrm{Var} \left\{ \mathrm{E} \left[ N | T \right] \right \}.
\]</span></p>
<p>To be more concrete, suppose that <span class="math inline">\(N_j\)</span> follows a Poisson distribution with the mean <span class="math inline">\(\lambda_j\)</span>, <span class="math inline">\(j=1,2\)</span>. Then we have</p>
<p><span class="math display">\[
\mathrm{Var}[N|T=j]= \mathrm{E}[N|T=j] = \lambda_j, \quad j = 1,2.
\]</span></p>
<p>Thus, we can derive the expectation of the conditional variance as</p>
<p><span class="math display">\[
\mathrm{E} \left\{ \mathrm{Var} \left[ N | T \right] \right \} = \alpha \lambda_1+ (1-\alpha) \lambda_2
\]</span></p>
<p>and the variance of the conditional expectation as</p>
<p><span class="math display">\[
\mathrm{Var} \left\{ \mathrm{E} \left[ N | T \right] \right \} = (\lambda_1-\lambda_2)^2 \alpha (1-\alpha).
\]</span></p>
<p>Note that the later is the variance for a Bernoulli with outcomes <span class="math inline">\(\lambda_1\)</span> and <span class="math inline">\(\lambda_2\)</span>, and the binomial probability <span class="math inline">\(\alpha\)</span>.</p>
<p>Based on the Law of Total Variance, the unconditional variance of <span class="math inline">\(N\)</span> is given by</p>
<p><span class="math display">\[
\mathrm{Var}[N]= \alpha \lambda_1+ (1-\alpha) \lambda_2 + (\lambda_1-\lambda_2)^2 \alpha (1-\alpha).
\]</span></p>
</div>
</div>
<div id="S:AppConjugateDistributions" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Conjugate Distributions<a href="CAppB.html#S:AppConjugateDistributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As described in Section <a href="#ChBayes:SecConjugate"><strong>??</strong></a>, for conjugate distributions the posterior and the prior come from the same family of distributions. In insurance applications, this broadly occurs in a family of distribution families known as the linear exponential family which we introduce first.</p>
<div id="linear-exponential-family" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Linear Exponential Family<a href="CAppB.html#linear-exponential-family" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Definition.</strong> The distribution function of the <em>linear exponential family</em> is</p>
<p><span class="math display">\[
f( x; \gamma ,\theta ) =
\exp \left( \frac{x\gamma -b(\gamma )}{\theta} +S\left( x,\theta \right) \right).
\]</span></p>
<p>Here, <span class="math inline">\(x\)</span> is a dependent variable and <span class="math inline">\(\gamma\)</span> is the parameter of interest. The quantity <span class="math inline">\(\theta\)</span> is a scale parameter. The term <span class="math inline">\(b(\gamma)\)</span> depends only on the parameter <span class="math inline">\(\gamma\)</span>, not the dependent variable. The statistic <span class="math inline">\(S\left(x,\theta \right)\)</span> is a function of the dependent variable and the scale parameter, not the parameter <span class="math inline">\(\gamma\)</span>.</p>
<p>The dependent variable <span class="math inline">\(x\)</span> may be discrete, continuous or a hybrid combination of the two. Thus, <span class="math inline">\(f\left( \cdot\right)\)</span> may be interpreted to be a density or mass function, depending on the application. <a href="#tab:18.1">Table 18.1</a> provides several examples, including the normal, binomial and Poisson distributions.</p>
<p><a id=tab:18.1></a></p>
<p>Table 18.1. <strong>Selected Distributions of the Linear Exponential Family</strong></p>
<p><span class="math display">\[
{\small
\begin{matrix}
\begin{array}{l|ccccc}
\hline
             &amp;             &amp; \text{Density or} &amp; &amp; &amp; \\
\text{Distribution} &amp; \text{Parameters} &amp; \text{Mass Function} &amp; \text{Components} \\
\hline \text{General} &amp; \gamma,~ \theta &amp;
\exp \left( \frac{x\gamma -b(\gamma )}{\theta} +S\left( x,\theta \right) \right) &amp;
\gamma,~ \theta, b(\gamma), S(x, \theta)\\
\text{Normal} &amp; \mu, \sigma^2  &amp;
\frac{1}{\sigma \sqrt{2\pi }}\exp \left(-\frac{(x-\mu )^{2}}{2\sigma ^{2}}\right) &amp;
\mu, \sigma^2, \frac{\gamma^2}{2}, - \left(\frac{x^2}{2\theta} + \frac{\log(2 \pi
\theta)}{2} \right) \\
\text{Binomal} &amp; \pi &amp;
{n \choose x} \pi ^x (1-\pi)^{n-x} &amp;
\log
\left(\frac{\pi}{1-\pi} \right), 1, n \log(1+e^{\gamma} ),  \\
&amp;  &amp;  &amp;  \log {n \choose x} \\
\text{Poisson} &amp; \lambda &amp;
\frac{\lambda^x}{x!} \exp(-\lambda)  &amp;
\log \lambda, 1, e^{\gamma}, - \log (x!)  \\
\text{Negative } &amp;
r,p &amp;  \frac{\Gamma(x+r)}{x!\Gamma(r)} p^r ( 1-p)^x &amp;
\log(1-p), 1, -r \log(1-e^{\gamma}), \\
~~~\text{Binomial}^{\ast} &amp; &amp; &amp; ~~~\log \left[ \frac{\Gamma(x+r)}{x!
\Gamma(r)} \right] \\
\text{Gamma} &amp; \alpha, \gamma  &amp; \frac{1}{\Gamma (\alpha)\gamma ^ \alpha}
x^{\alpha -1 }\exp(-x/ \gamma)  &amp; - \frac{\gamma}{\alpha },
\frac{1}{\alpha}, - \log ( - \gamma), -\gamma^{-1} \log \gamma \\
&amp; &amp; &amp;  - \log \left( \Gamma(\gamma ^{-1}) \right) +
(\gamma^{-1} - 1) \log x &amp; &amp; \\ \hline
\end{array}\\
^{\ast} \text{This assumes that the parameter r is fixed but need not be an integer.}\\
\end{matrix}
}
\]</span></p>
<p>The Tweedie (see Section <a href="#S:AggLoss:Tweedie"><strong>??</strong></a>) and inverse Gaussian distributions are also members of the linear exponential family. The linear exponential family of distribution families is extensively used as the basis of generalized linear models as described in, for example, <span class="citation">Frees (<a href="bibliography.html#ref-frees2009regression">2009</a>)</span>.</p>
</div>
<div id="S:IterExp:Conjugate" class="section level3 hasAnchor" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> Conjugate Distributions<a href="CAppB.html#S:IterExp:Conjugate" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now assume that the parameter <span class="math inline">\(\gamma\)</span> is random with distribution <span class="math inline">\(\pi(\gamma, \tau)\)</span>, where <span class="math inline">\(\tau\)</span> is a vector of parameters that describe the distribution of <span class="math inline">\(\gamma\)</span>. In Bayesian models, the distribution <span class="math inline">\(\pi\)</span> is known as the prior and reflects our belief or information about <span class="math inline">\(\gamma\)</span>. The likelihood <span class="math inline">\(f(x|\gamma)\)</span> is a probability conditional on <span class="math inline">\(\gamma\)</span>. The distribution of <span class="math inline">\(\gamma\)</span> with knowledge of the random variables, <span class="math inline">\(\pi(\gamma,\tau| x)\)</span>, is called the posterior distribution. For a given likelihood distribution, priors and posteriors that come from the same parametric family are known as conjugate families of distributions.</p>
<p>For a linear exponential likelihood, there exists a natural conjugate family. Specifically, consider a likelihood of the form
<span class="math inline">\(f(x|\gamma) = \exp \left\{(x\gamma -b(\gamma))/\theta\right\} \exp \left\{S\left( x,\theta \right) \right\}\)</span>. For this likelihood, define the prior distribution
<span class="math display">\[
\pi(\gamma,\tau) = C \exp\left\{
\gamma a_1(\tau) - b(\gamma)a_2(\tau))\right\},
\]</span>
where <span class="math inline">\(C\)</span> is a normalizing constant. Here, <span class="math inline">\(a_1(\tau)=a_1\)</span> and <span class="math inline">\(a_2(\tau)=a_2\)</span> are functions of the parameters <span class="math inline">\(\tau\)</span> although we simplify the notation by dropping explicit dependence on <span class="math inline">\(\tau\)</span>. The joint distribution of <span class="math inline">\(x\)</span> and <span class="math inline">\(\gamma\)</span> is given by <span class="math inline">\(f(x,\gamma) = f(x|\gamma) \pi(\gamma,\tau)\)</span>. Using Bayes Theorem, the
posterior distribution is
<span class="math display">\[
\pi(\gamma,\tau|x) = C_1 \exp\left\{
\gamma \left( a_1+\frac{x}{\theta}\right) - b(\gamma)\left( a_2+\frac{1}{\theta}\right)\right\},
\]</span>
where <span class="math inline">\(C_1\)</span> is a normalizing constant. Thus, we see that <span class="math inline">\(\pi(\gamma,\tau|x)\)</span> has the same form as <span class="math inline">\(\pi(\gamma,\tau)\)</span>.</p>
<hr />
<p><strong>Special case. Gamma-Poisson Model.</strong> Consider a Poisson likelihood so that <span class="math inline">\(b(\gamma) = e^{\gamma}\)</span> and scale parameter (<span class="math inline">\(\theta\)</span>) equals one. Thus, we have
<span class="math display">\[
\pi(\gamma,\tau) = C \exp\left\{
\gamma a_1 - a_2 e^{\gamma} \right\}=
C ~
\left(
e^{\gamma}\right)^{a_1}
\exp\left(-a_2e^{\gamma} \right).
\]</span>
From the table of exponential family distributions, we recognize this to be a gamma distribution. That is, we have that the prior distribution of <span class="math inline">\(\lambda = e^{\gamma}\)</span> is a gamma distribution with parameters <span class="math inline">\(\alpha_{prior} = a_1+1\)</span> and <span class="math inline">\(\theta_{prior}^{-1}=a_2\)</span>. The posterior distribution is a gamma distribution with parameters <span class="math inline">\(\alpha_{post} =a_1+x+1=\alpha_{prior}+x\)</span> and <span class="math inline">\(\theta_{post}^{-1}=a_2+1 = \theta_{prior}^{-1}+1\)</span>.</p>
<hr />
<p><strong>Special case. Normal-Normal Model.</strong>
Consider a normal likelihood so that <span class="math inline">\(b(\gamma) = \gamma^2/2\)</span> and the scale parameter is <span class="math inline">\(\sigma^2\)</span>. Thus, we have
<span class="math display">\[
\pi(\gamma,\tau) = C \exp\left\{
\gamma a_1 - \frac{\gamma^2}{2}a_2\right\}=
C_1(\tau)\exp\left\{ - \frac{a_2}{2}\left(\gamma -\frac{a_1}{a_2}\right)^2\right\},
\]</span>
The prior distribution of <span class="math inline">\(\gamma\)</span> is normal with mean <span class="math inline">\(a_1/a_2\)</span> and variance <span class="math inline">\(a_2^{-1}\)</span>. The posterior distribution of <span class="math inline">\(\gamma\)</span> given <span class="math inline">\(x\)</span> is normal with mean <span class="math inline">\((a_1+x/\sigma^2)/(a_2+\sigma^{-2})\)</span> and variance <span class="math inline">\((a_2+\sigma^{-2})^{-1}\)</span>.</p>
<hr />
<p><strong>Special case. Beta-Binomial Model.</strong> Consider a binomial likelihood so that <span class="math inline">\(b(\gamma) = n \log(1+e^{\gamma})\)</span> and scale parameter equals one. Thus, we have
<span class="math display">\[
\pi(\gamma,\tau) = C \exp\left\{
\gamma a_1 - n a_2 \log(1+e^{\gamma}) \right\}=
C ~
\left(
\frac{e^{\gamma}}{1+e^{\gamma}}\right)^{a_1}
\left(1-\frac{e^{\gamma}}{1+e^{\gamma}}\right)^{-na_2+a_1}.
\]</span></p>
<p>This is a beta distribution. As in the other cases, prior parameters <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span> are updated to become posterior parameters <span class="math inline">\(a_1+x\)</span> and <span class="math inline">\(a_2+1\)</span>.</p>
<div id="contributors-2" class="section level4 unnumbered hasAnchor">
<h4>Contributors<a href="CAppB.html#contributors-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Lei (Larry) Hua</strong>, Northern Illinois University, and <strong>Edward W. (Jed) Frees</strong>, University of Wisconsin-Madison, are the principal authors of the initial version of this chapter. Email: <a href="mailto:lhua@niu.edu" class="email">lhua@niu.edu</a> or <a href="mailto:jfrees@bus.wisc.edu" class="email">jfrees@bus.wisc.edu</a> for chapter comments and suggested improvements.
<ul>
<li>The chapter was reviewed by Benjamin Ct.</li>
</ul></li>
</ul>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="CAppA.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="CAppC.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["LossDataAnalytics.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
